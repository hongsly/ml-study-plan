[
  {
    "index": 4,
    "question": "Wha's Yoav Goldberg's contributiin to informatio retrieval?",
    "reference": "Yoav Goldberg contributed to information retrieval through his work on Multi-passage BERT and Break it down: A question understanding benchmark.",
    "contexts": [
      "AAAI)_ .\n\n\nZhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, and Bing Xiang. 2019. Multi-passage BERT:\nA globally normalized bert model for open-domain\nquestion answering. In _Empirical Methods in Natu-_\n_ral Language Processing (EMNLP)_ .\n\n\nTomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg, Daniel Deutch, and Jonathan\nBerant. 2020. Break it down: A question understanding benchmark. _Transactions of the Associa-_\n_tion of Computational Linguistics (TACL)_ .\n\n\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\nJialin Liu, Paul Bennett, Junaid Ahmed, and Arnold\nOverwijk. 2020a. Approximate nearest neighbor\nnegative contrastive learning for dense text retrieval.\n_ArXiv_, abs/2007.00808.\n\n\nWenhan Xiong, Hankang Wang, and William Yang\nWang. 2020b. Progressively pretrained dense corpus\nindex for open-domain question answering. _ArXiv_,\nabs/2005.00038.\n\n\nWei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen\nTan, Kun Xiong, Ming Li, and Jimmy Lin. 2019a.\nEnd-to-end open-domain question answering with\nbertserini. In _North American Association for Com-_\n_putational Linguistics (NAACL)_, pages 72\u201377.\n\n\nWei Yang, Yuqing Xie, Luchen Tan, Kun Xiong, Ming\nLi, and Jimmy Lin. 2019b. Data augmentation for\nbert fine-tuning in open-domain question answering.\n_ArXiv_, abs/1904.06652.\n\n\nWen-tau Yih, Kristina Toutanova, John C Platt, and\nChristopher Meek. 2011. Learning discriminative\nprojections for text similarity measures. In _Com-_\n_putational Natural Language Learning (CoNLL)_,\npages 247\u2013256.\n\n\n**A** **Distant Supervision**\n\n\nWhen training our final DPR model using Natural\nQuestions, we use the passages in our collection\nthat best match the gold context as the positive\npassages. As some QA datasets contain only the\nquestion"
    ],
    "query_style": "MISSPELLED",
    "query_length": "LONG"
  },
  {
    "index": 5,
    "question": "What is the purpose of Antoine Bordes' work in machine learning?",
    "reference": "Antoine Bordes worked on developing models for reading Wikipedia to answer open-domain questions.",
    "contexts": [
      " descent. In\n_Proceedings of the 22nd international conference on_\n_Machine learning_, pages 89\u201396.\n\n\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine\nBordes. 2017. Reading Wikipedia to answer opendomain questions. In _Association for Computa-_\n_tional Linguistics (ACL)_, pages 1870\u20131879.\n\n\nRajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,\nand Andrew McCallum. 2019. Multi-step retrieverreader interaction for scalable open-domain question\nanswering. In _International Conference on Learn-_\n_ing Representations (ICLR)_ .\n\n\nScott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman.\n1990. Indexing by latent semantic analysis. _Jour-_\n_nal of the American society for information science_,\n41(6):391\u2013407.\n\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language understanding. In _North American Association for Com-_\n_putational Linguistics (NAACL)_ .\n\n\nDavid A Ferrucci. 2012. Introduction to \u201cThis is Watson\u201d. _IBM Journal of Research and Development_,\n56(3.4):1\u20131.\n\n\nDaniel Gillick, Sayali Kulkarni, Larry Lansing,\nAlessandro Presta, Jason Baldridge, Eugene Ie, and\nDiego Garcia-Olano. 2019. Learning dense representations for entity retrieval. In _Computational Nat-_\n_ural Language Learning (CoNLL)_ .\n\n\nRuiqi Guo, Sanjiv Kumar, Krzysztof Choromanski, and\nDavid Simcha. 2016. Quantization based fast inner\nproduct search. In _Artificial Intelligence and Statis-_\n_tics_, pages 482\u2013490.\n\n\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020. REALM:\nRetrieval-augmented language model pre-training.\n_ArXiv_, abs/2002.08909.\n\n\nMatthew Henderson, Rami Al-Rfou, Brian Strope, Yunhsuan Sung, L"
    ],
    "query_style": "MISSPELLED",
    "query_length": "MEDIUM"
  },
  {
    "index": 14,
    "question": "What is the difference between ARES and other retrieval-augmented generation evaluation systems like Data ChatGPT LLaMA Expansion SFT?",
    "reference": "ARES, an Automated RAG Evaluation System, evaluates RAG systems along dimensions of context relevance, answer faithfulness, and answer relevance. It finetunes lightweight LM judges to assess the quality of individual RAG components and utilizes a small set of human-annotated datapoints for prediction-powered inference (PPI). Data ChatGPT LLaMA Expansion SFT is not explicitly mentioned in the provided context.",
    "contexts": [
      "<1-hop>\n\n## **ARES: An Automated Evaluation Framework for Retrieval-Augmented** **Generation Systems**\n\n\n\n**Jon Saad-Falcon**\nStanford University _[\u2217]_\n\njonsaadfalcon@stanford.edu\n\n\n**Christopher Potts**\nStanford University\ncgpotts@stanford.edu\n\n\n**Abstract**\n\n\nEvaluating retrieval-augmented generation\n(RAG) systems traditionally relies on hand\nannotations for input queries, passages to retrieve, and responses to generate. We introduce ARES, an _Automated RAG Evaluation_\n_System_, for evaluating RAG systems along\nthe dimensions of context relevance, answer\nfaithfulness, and answer relevance. By creating its own synthetic training data, ARES\nfinetunes lightweight LM judges to assess the\nquality of individual RAG components. To\nmitigate potential prediction errors, ARES utilizes a small set of human-annotated datapoints\nfor prediction-powered inference (PPI). Across\neight different knowledge-intensive tasks in\nKILT, SuperGLUE, and AIS, ARES accurately\nevaluates RAG systems while using only a few\nhundred human annotations during evaluation.\nFurthermore, ARES judges remain effective\nacross domain shifts, proving accurate even\nafter changing the type of queries and/or documents used in the evaluated RAG systems. We\nmake our code and datasets publicly available\n\n[on Github.](https://github.com/stanford-futuredata/ARES)\n\n\n**1** **Introduction**\n\n\nRetrieval-augmented generation (RAG) has become a prominent approach for building userfacing NLP applications, such as systems for question answering (QA), fact-checking, and customer\nsupport (Petroni et al., 2021; Wang et al., 2019).\nTypically, a RAG system consists of a retriever and\na downstream language model (LM). Given a user\nquestion, the retriever finds relevant passages from\na corpus and the LM uses these passages to generate a response. This formulation admits a multitude\n\n- f choices: what retrieval model to use, how to di\nvide the documents into retrieval chunks, and how\nto prompt or finetune the LM to use the retrieved\ninformation, to name only a few of the simplest\ndesign decisions.\n\n\n_\u2217_ Project started during research internship at Databricks\n\n\n\n**Omar Khattab**\n\nStanford University\n\n   - khattab",
      "<2-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 15,
    "question": "What is the purpose of Temporalwiki and how does it relate to the development of language models like LLaMA?",
    "reference": "Temporalwiki is a lifelong benchmark for training and evaluating ever-evolving language models. It relates to the development of language models like LLaMA by providing a platform for continuous learning and improvement, ensuring that these models can adapt and evolve over time.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nbo Shin, Janghoon Han, Gyeonghun Kim, and\nMinjoon Seo. 2022. Temporalwiki: A lifelong benchmark for training and evaluating ever-evolving language models.\n\n\nZhengbao Jiang, Luyu Gao, Jun Araki, Haibo Ding,\nZhiruo Wang, Jamie Callan, and Graham Neubig.\n2022. Retrieval as attention: End-to-end learning of\nretrieval and reading within a single transformer. In\n_Conference on Empirical Methods in Natural Lan-_\n_guage Processing (EMNLP)_, Abu Dhabi, UAE.\n\n\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\n[Wen-tau Yih. 2020. Dense passage retrieval for open-](https://doi.org/10.18653/v1/2020.emnlp-main.550)\n[domain question answering. In](https://doi.org/10.18653/v1/2020.emnlp-main.550) _Proceedings of the_\n_2020 Conference on Empirical Methods in Natural_\n_Language Processing (EMNLP)_, pages 6769\u20136781,\nOnline. Association for Computational Linguistics.\n\n\nOmar Khattab, Keshav Santhanam, Xiang Lisa\nLi, David Hall, Percy Liang, Christopher Potts,\nand Matei Zaharia. 2022. Demonstrate-searchpredict: Composing retrieval and language models for knowledge-intensive NLP. _arXiv preprint_\n_arXiv:2212.14024_ .\n\n\n\nMojtaba Komeili, Kurt Shuster, and Jason Weston. 2022.\n\n[Internet-augmented dialogue generation. In](https://doi.org/10.18653/v1/2022.acl-long.579) _Proceed-_\n_ings of the 60th Annual Meeting of the Association_\n_for Computational Linguistics (Volume 1: Long Pa-_\n_pers)_, pages 8460\u20138478, Dublin, Ireland. Association\nfor Computational Linguistics.\n\n\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 16,
    "question": "What were the speed and memory benchmarks for the SSM scan operation in the context of the Mamba model?",
    "reference": "The speed of the SSM scan operation (state expansion _\ud835\udc41_ = 16) was faster than the best attention implementation that we know of (FlashAttention-2 (Dao 2024)) beyond sequence length 2K, and up to 20-40\u00d7 faster than a standard scan implementation in PyTorch. Mamba achieved 4-5\u00d7 higher inference throughput than a Transformer of similar size, since without the KV cache it can use much higher batch sizes.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nTest    -    - 0 _._ 02 8 _._ 33 257 _._ 6 0 _._ 19\n\n\n**4.5** **Speed and Memory Benchmarks**\n\n\n\nTable 5: ( **SC09 Model Ablations** ) Models with 6M parameters. In\nSaShiMi\u2019s U-Net backbone, there are 8 center blocks operating on\nsequence length 1000, sandwiched on each side by 8 outer blocks on\nsequence length 4000, sandwiched by 8 outer blocks on sequence\nlength 16000 (40 blocks total). The architecture of the 8 center\nblocks are ablated independently of the rest. Note that Transformers\n(MHA+MLP) were not tested in the more important outer blocks\nbecause of efficiency constraints.\n\n\nOuter Center NLL \u2193 FID \u2193 IS \u2191 mIS \u2191 AM \u2193\n\n\nS4+MLP MHA+MLP 1.859 1.45 5.06 47.03 0.70\n\nS4+MLP S4+MLP 1.867 1.43 5.42 53.54 0.65\n\nS4+MLP Mamba 1.859 1.42 5.71 56.51 0.64\n\nMamba MHA+MLP **1.850** 1.37 5.63 58.23 0.62\n\nMamba S4+MLP 1.853 1.07 6.05 73.34 0.55\n\nMamba Mamba 1.852 **0.94** **6.26** **88.54** **0.52**\n\n\n\nWe benchmark the speed of the SSM scan operation (state expansion _\ud835\udc41_ = 16), as well as the end-to-end inference\nthroughput of Mamba, in Figure 8. Our efficient SSM scan is faster than the best attention implementation that we know of\n(FlashAttention-2 (Dao 2024)) beyond sequence length 2K, and up to 20-40\u00d7 faster than a standard scan implementation\nin PyTorch. Mamba achieves 4-5\u00d7 higher inference throughput than a Transformer of similar size, since without the\nKV cache it can use much higher batch sizes. For example, a Mamba-6."
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 18,
    "question": "What is the role of dialogue generation in expanding and improving language models like LLaMA?",
    "reference": "Dialogue generation plays a crucial role in expanding and improving language models like LLaMA by providing labeled data for supervised fine-tuning (SFT). This process involves using human conversations to train models, enhancing their ability to understand and generate natural language responses.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\n D.; Wang, Y.; Bi, W.; Tu, Z.; Liu, X.; Lam, W.; and\nShi, S. 2019a. Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory. In _Proceedings of the_\n_2019 Conference of the North American Chapter of the As-_\n_sociation for Computational Linguistics: Human Language_\n_Technologies, Volume 1 (Long and Short Papers)_, 1219\u2013\n1228. Minneapolis, Minnesota: Association for Computational Linguistics.\n\nCai, D.; Wang, Y.; Bi, W.; Tu, Z.; Liu, X.; and Shi, S.\n2019b. Retrieval-guided Dialogue Response Generation via\na Matching-to-Generation Framework. In _Proceedings of_\n_the 2019 Conference on Empirical Methods in Natural Lan-_\n_guage Processing and the 9th International Joint Confer-_\n_ence on Natural Language Processing (EMNLP-IJCNLP)_,\n1866\u20131875. Hong Kong, China: Association for Computational Linguistics.\n\nCao, M.; Dong, Y.; Wu, J.; and Cheung, J. C. K. 2020. Factual Error Correction for Abstractive Summarization Models. In _Proceedings of the 2020 Conference on Empirical_\n_Methods in Natural Language Processing (EMNLP)_, 6251\u2013\n6258. Online: Association for Computational Linguistics.\n\nChang, Y.; Wang, X.; Wang, J.; Wu, Y.; Yang, L.; Zhu,\nK.; Chen, H.; Yi, X.; Wang, C.; Wang, Y.; Ye, W.;\nZhang, Y.; Chang, Y.; Yu, P. S.; Yang, Q.; and Xie, X.\n2023. A Survey on Evaluation of Large Language Models.\narXiv:2307.03109.\n\n\n\nChiang, W.-L.; Li, Z.; Lin, Z.; Sheng, Y.; Wu, Z.; Zhang, H.;\nZheng, L.; Zhuang, S.; Zhuang, Y.; Gonzalez, J. E.; Stoica,\nI.; and Xing, E. P. 2023. Vicuna: An Open-Source Chatbot\nImpressing GPT-4 with 90%* ChatGPT Quality.\nCui, J.; Li,"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 19,
    "question": "What open-domain QA models use dense retrieval techniques and how do they compare to traditional IR methods?",
    "reference": "Open-domain QA models that use dense retrieval techniques typically employ dense passage retrieval methods, which better capture semantic matching beyond simple n-gram overlaps. These methods either conduct large-scale pretraining with self-supervised tasks close to the underlying question-passage matching or directly finetune pretrained masked language models using human-labeled question-passage pairs. On single-hop information-seeking QA datasets like NaturalQuestions or WebQuestions, these dense methods have achieved significant improvements over traditional IR methods. Prior to these model-based methods, Das et al. (2019) used RNN encoders for generating dense representations of questions and passages, involving an iterative retrieval process and reformulating the query representation based on reader model's hidden states. However, their method required an initial round of TF-IDF/BM25 retrieval and a sophisticated RL-based training paradigm to work well. Unlike Feldman & El-Yaniv (2019)'s bi-attentive reformulation component applied on token-level representations, our approach uses a straightforward query reformulation strategy by concatenating the original query and previous retrieval as inputs to the query encoder. Together with stronger pretrained encoders and more effective training methods, MDR doubles the accuracy of their system.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nPublished as a conference paper at ICLR 2021\n\n\n4 RELATED WORK\n\n\n**Open-domain QA with Dense Retrieval** In contrast to sparse term-index IR methods that are\nwidely used by existing open-domain QA systems (Chen et al., 2017; Wang et al., 2018; Yang\net al., 2019), recent systems (Lee et al., 2019; Guu et al., 2020; Karpukhin et al., 2020) typically\nuses dense passage retrieval techniques that better capture the semantic matching beyond simple\nn-gram overlaps. To generate powerful dense question and passage representations, these methods\neither conduct large-scale pretraining with self-supervised tasks that are close to the underlying\nquestion-passage matching in retrieval, or directly use the human-labeled question-passage pairs\nto finetune pretrained masked language models. On single-hop information-seeking QA datasets\nsuch as NaturalQuestions (Kwiatkowski et al., 2019) or WebQuestions (Berant et al., 2013), these\ndense methods have achieved significant improvements over traditional IR methods. Prior to these\nmethods based on pretrained models, Das et al. (2019) use RNN encoder to get dense representations\n\n- f questions and passages. They also consider an iterative retrieval process and reformulate the query\nrepresentation based on reader model\u2019s hidden states. However, their method requires an initial round\n\n- f TF-IDF/BM25 retrieval and a sophisticated RL-based training paradigm to work well. Finally, like\nthe aforementioned methods, only single-hop datasets are considered in their experiments. More akin\nto our approach, Feldman & El-Yaniv (2019) use a similar recursive dense retrieval formulation for\nmulti-hop QA. In contrast to their biattenional reformulation component, which is applied on top of\nthe token-level representations of the query and passages, we adopt a more straightforward query\nreformulation strategy, by simply concatenating the original query and previous retrieval as the inputs\nto the query encoder. Together with stronger pretrained encoders and more effective training methods\n(in-batch + memory bank negative sampling vs their binary ranking loss), MDR is able to double the\naccuracy of their system.\n\n\n**Query Expansion Techniques in IR** As our dense encoder augments the original question with\nthe initial retrieved results to form the updated query representation, our work is also relevant to query\n"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 20,
    "question": "What is the relationship between Selective State Space Models and linear attention approximations like SSMs?",
    "reference": "Selective State Space Models (SSMs) are related to linear attention approximations such as SSMs through their ability to handle time-varying data efficiently. They can be viewed as an architecture with an SSM sandwiched by two gated connections, which allows for parallelizable computation paths and the use of simpler mechanisms like multi-head attention instead of convolutions.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nKatharopoulos et al. 2020) is an approximation of self-attention involving a recurrence which can be\nviewed as a degenerate linear SSM.\n\n\n- H3 (Dao, Fu, Saab, et al. 2023) generalized this recurrence to use S4; it can be viewed as an architecture with an SSM\nsandwiched by two gated connections (Figure 3). H3 also inserts a standard local convolution, which they frame as a\nshift-SSM, before the main SSM layer.\n\n\n- Hyena (Poli et al. 2023) uses the same architecture as H3 but replaces the S4 layer with an MLP-parameterized global\nconvolution (Romero et al. 2021).\n\n\n- RetNet (Y. Sun et al. 2023) adds an additional gate to the architecture and uses a simpler SSM, allowing an alternative\nparallelizable computation path, using a variant of multi-head attention (MHA) instead of convolutions.\n\n\n- RWKV (B. Peng et al. 2023) is a recent RNN designed for language modeling based on another linear attention approximation, the attention-free Transformer (S. Zhai et al. 2021). Its main \u201cWKV\u201d mechanism involves LTI recurrences and\ncan be viewed as the ratio of two SSMs.\n\n\nOther closely related SSMs and architectures are discussed further in an extended related work (Appendix B). We highlight\nin particular S5 (Smith, Warrington, and Linderman 2023), QRNN (Bradbury et al. 2016), and SRU (Lei et al. 2017), which\nwe view as the most closely related methods to our core selective SSM.\n\n\n4\n\n\n### **3 Selective State Space Models**\n\nWe motivate our selection mechanism using intuition from synthetic tasks (Section 3.1), then explain how to incorporate\nthis mechanism into state space models (Section 3.2). The resulting time-varying SSMs cannot use convolutions, presenting\na technical challenge of how to compute them efficiently. We overcome this with a hardware-aware algorithm that exploits\nthe memory hierarchy on modern hardware (Section 3.3). We then describe a simple SSM architecture without attention or\neven MLP blocks (Section 3.4). Finally, we discuss some additional properties of selection mechanisms (Section 3."
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 21,
    "question": "What is the generate-and-retrieve method and how does it improve information retrieval for semantic parsing?",
    "reference": "The generate-and-retrieve method involves using predictions to enhance retrieval for semantic parsing. This approach was introduced in a paper titled 'Generate-and-retrieve: Use your predictions to improve retrieval for semantic parsing' by Yury Zemlyanskiy, Michiel de Jong, Joshua Ainslie, Panupong Pasupat, Peter Shaw, Linlu Qiu, Sumit Shanghai, and Fei Sha. The method leverages iterative retrieval and generation techniques to expand the capabilities of existing models like ChatGPT and LLaMA for better performance in semantic parsing tasks.",
    "contexts": [
      "<1-hop>\n\nhttps://doi.org/10.48550/arXiv.2305.14002)\n_CoRR_, abs/2305.14002.\n\n\nYury Zemlyanskiy, Michiel de Jong, Joshua Ainslie,\nPanupong Pasupat, Peter Shaw, Linlu Qiu, Sumit\n[Sanghai, and Fei Sha. 2022. Generate-and-retrieve:](https://aclanthology.org/2022.coling-1.438)\n[Use your predictions to improve retrieval for seman-](https://aclanthology.org/2022.coling-1.438)\n[tic parsing. In](https://aclanthology.org/2022.coling-1.438) _Proceedings of the 29th International_\n_Conference on Computational Linguistics, COLING_\n_2022, Gyeongju, Republic of Korea, October 12-17,_\n_2022_, pages 4946\u20134951. International Committee on\nComputational Linguistics.\n\n\n\nFengji Zhang, Bei Chen, Yue Zhang, Jin Liu, Daoguang\nZan, Yi Mao, Jian-Guang Lou, and Weizhu Chen.\n[2023. Repocoder: Repository-level code completion](https://doi.org/10.48550/arXiv.2303.12570)\n[through iterative retrieval and generation.](https://doi.org/10.48550/arXiv.2303.12570) _CoRR_,\nabs/2303.12570.\n\n\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022. Opt: Open\npre-trained transformer language models. _ArXiv_,\nabs/2205.01068.\n\n\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du,\nChen Yang, Yushuo Chen, Zhip",
      "<2-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 22,
    "question": "What is the fine-tuning approach used in Temporalwiki?",
    "reference": "The fine-tuning approach used in Temporalwiki involves training and evaluating ever-evolving language models over time.",
    "contexts": [
      "<1-hop>\n\n which unfortunately can easily go beyond\nthe input length limit of in-context learning. We explore the fine-tuning approach on HotpotQA\n\n\n6Human feedback can also be incorporated in a complementary manner but we leave it for future work.\n\n\n9\n\n\nPublished as a conference paper at ICLR 2023\n\n\nwith initial promising results, but learning from more high-quality human annotations will be the\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\ncombining it with complementary paradigms like reinforcement learning could result in stronger\nagents that further unlock the potential of LLMs for more applications.\n\n\nACKNOWLEDGMENTS\n\n\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\nGroup. This work was supported in part by the National Science Foundation under Grant No.\n2107048. Any opinions, findings, and conclusions or recommendations expressed in this material are\nthose of the author(s) and do not necessarily reflect the views of the National Science Foundation.\n\n\nREPRODUCIBILITY STATEMENT\n\n\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible\nmodel yet. To increase reproducibility, we have included all used prompts in Appendix C, additional\nexperiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct\n[prompting code at https://anonymous.4open.science/r/ReAct-2268/.](https://anonymous.4open.science/r/ReAct-2268/)\n\n\nETHICS STATEMENT\n\n\nReAct prompts large language models to generate more human interpretable, diagnosable, and\ncontrollable task-solving trajectories than previous methods. However, hooking up a large language\nmodel with an action space to interact with external environments (e.g. the web, physical environments) has potential dangers, e.g. looking up inappropriate or private information, or taking harmful\nactions in an environment. Our experiments minimize such risks by limiting the interactions to\nspecific websites (Wikipedia or WebShop) that are free of private information, without any dangerous\nactions in the action space design (i.e. models cannot really buy products on WebShop the research\nbenchmark, or edit Wikipedia). We believe researchers should be aware of such risks before designing\nmore extensive experiments in the future.\n\n\nREFERENCES\n\n\nJosh Abramson, Ar",
      "<2-hop>\n\nbo Shin, Janghoon Han, Gyeonghun Kim, and\nMinjoon Seo. 2022. Temporalwiki: A lifelong benchmark for training and evaluating ever-evolving language models.\n\n\nZhengbao Jiang, Luyu Gao, Jun Araki, Haibo Ding,\nZhiruo Wang, Jamie Callan, and Graham Neubig.\n2022. Retrieval as attention: End-to-end learning of\nretrieval and reading within a single transformer. In\n_Conference on Empirical Methods in Natural Lan-_\n_guage Processing (EMNLP)_, Abu Dhabi, UAE.\n\n\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\n[Wen-tau Yih. 2020. Dense passage retrieval for open-](https://doi.org/10.18653/v1/2020.emnlp-main.550)\n[domain question answering. In](https://doi.org/10.18653/v1/2020.emnlp-main.550) _Proceedings of the_\n_2020 Conference on Empirical Methods in Natural_\n_Language Processing (EMNLP)_, pages 6769\u20136781,\nOnline. Association for Computational Linguistics.\n\n\nOmar Khattab, Keshav Santhanam, Xiang Lisa\nLi, David Hall, Percy Liang, Christopher Potts,\nand Matei Zaharia. 2022. Demonstrate-searchpredict: Composing retrieval and language models for knowledge-intensive NLP. _arXiv preprint_\n_arXiv:2212.14024_ .\n\n\n\nMojtaba Komeili, Kurt Shuster, and Jason Weston. 2022.\n\n[Internet-augmented dialogue generation. In](https://doi.org/10.18653/v1/2022.acl-long.579) _Proceed-_\n_ings of the 60th Annual Meeting of the Association_\n_for Computational Linguistics (Volume 1: Long Pa-_\n_pers)_, pages 8460\u20138478, Dublin, Ireland. Association\nfor Computational Linguistics.\n\n\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 23,
    "question": "What were the speed and memory benchmarks for the Mamba model in comparison to other models?",
    "reference": "The Mamba model achieved 4-5\u00d7 higher inference throughput than a Transformer of similar size, as it can use much higher batch sizes without the KV cache. It was faster than the best attention implementation that we know of (FlashAttention-2) beyond sequence length 2K, and up to 20-40\u00d7 faster than a standard scan implementation in PyTorch.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nTest    -    - 0 _._ 02 8 _._ 33 257 _._ 6 0 _._ 19\n\n\n**4.5** **Speed and Memory Benchmarks**\n\n\n\nTable 5: ( **SC09 Model Ablations** ) Models with 6M parameters. In\nSaShiMi\u2019s U-Net backbone, there are 8 center blocks operating on\nsequence length 1000, sandwiched on each side by 8 outer blocks on\nsequence length 4000, sandwiched by 8 outer blocks on sequence\nlength 16000 (40 blocks total). The architecture of the 8 center\nblocks are ablated independently of the rest. Note that Transformers\n(MHA+MLP) were not tested in the more important outer blocks\nbecause of efficiency constraints.\n\n\nOuter Center NLL \u2193 FID \u2193 IS \u2191 mIS \u2191 AM \u2193\n\n\nS4+MLP MHA+MLP 1.859 1.45 5.06 47.03 0.70\n\nS4+MLP S4+MLP 1.867 1.43 5.42 53.54 0.65\n\nS4+MLP Mamba 1.859 1.42 5.71 56.51 0.64\n\nMamba MHA+MLP **1.850** 1.37 5.63 58.23 0.62\n\nMamba S4+MLP 1.853 1.07 6.05 73.34 0.55\n\nMamba Mamba 1.852 **0.94** **6.26** **88.54** **0.52**\n\n\n\nWe benchmark the speed of the SSM scan operation (state expansion _\ud835\udc41_ = 16), as well as the end-to-end inference\nthroughput of Mamba, in Figure 8. Our efficient SSM scan is faster than the best attention implementation that we know of\n(FlashAttention-2 (Dao 2024)) beyond sequence length 2K, and up to 20-40\u00d7 faster than a standard scan implementation\nin PyTorch. Mamba achieves 4-5\u00d7 higher inference throughput than a Transformer of similar size, since without the\nKV cache it can use much higher batch sizes. For example, a Mamba-6."
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 24,
    "question": "What is the process of Data ChatGPT LLaMA Expansion SFT and how does it contribute to the democratization of AI?",
    "reference": "Data ChatGPT LLaMA Expansion SFT involves expanding a pre-trained model like LLaMA using a dataset, which then undergoes fine-tuning. This process contributes to the democratization of AI by making advanced capabilities more accessible to smaller entities and individual researchers.",
    "contexts": [
      "<1-hop>\n\n learning from the\nproprietary models that have been extensively trained and\nfine-tuned in these areas.\nThe benefits of knowledge distillation in the era of\nLLMs are multifaceted and transformative (Gu et al., 2024).\nThrough a suite of distillation techniques, the gap between\nproprietary and open-source models is significantly narrowed (Chiang et al., 2023; Xu et al., 2023a) and even\nfilled (Zhao et al., 2023a). This process not only streamlines\ncomputational requirements but also enhances the environmental sustainability of AI operations, as open-source models become more proficient with lesser computational overhead. Furthermore, knowledge distillation fosters a more\naccessible and equitable AI landscape, where smaller entities and individual researchers gain access to state-of-the-art\ncapabilities, encouraging wider participation and diversity\nin AI advancements. This democratization of technology\nleads to more robust, versatile, and accessible AI solutions,\ncatalyzing innovation and growth across various industries\nand research domains.\n\nThe escalating need for a comprehensive survey on the\nknowledge distillation of LLMs stems from the rapidly\nevolving landscape of AI (OpenAI et al., 2023; Team et al.,\n2023) and the increasing complexity of these models. As AI\ncontinues to penetrate various sectors, the ability to efficiently and effectively distill knowledge from proprietary\nLLMs to open-source ones becomes not just a technical\naspiration but a practical necessity. This need is driven by\nthe growing demand for more accessible, cost-effective, and\nadaptable AI solutions that can cater to a diverse range\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFig. 2: An overview of this survey on knowledge distillation of large language models. Note that \u2018Section\u2019 is abbreviated\nas \u2018Sec.\u2019 in this figure. RM _S_ ( _\u00b7_ ) denotes the student reward model. 1 _\u20dd\u20dd_ 2 _\u20dd_ 3 _\u20dd_ 4 denote the steps in KD of LLMs.\n\n\n\n\n- f applications and users. A survey in this field is vital\nfor synthesizing the current methodologies, challenges, and\nbreakthroughs in knowledge distillation. It may serve as a\nbeacon for researchers and practitioners alike, guiding them\nto distill complex AI capabilities into more manageable and\naccessible forms. Moreover, such a survey can illuminate the\npath forward, identifying gaps",
      "<2-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 25,
    "question": "What are some examples of downstream models that have been expanded and fine-tuned using the Data ChatGPT LLaMA Expansion SFT method?",
    "reference": "Some examples of downstream models that have been expanded and fine-tuned using the Data ChatGPT LLaMA Expansion SFT method include MiniLLM, Self-Align, Self-Rewarding, STaR, Llama-GPT4, Reflection-Tuning, Selective Reflection-Tuning, Vicuna, Koala, Baize, UltraChat, and Orca2.",
    "contexts": [
      "<1-hop>\n\ndownstream models, our system can match the best published result while being 10x faster.\n\n\n2 METHOD\n\n\n2.1 PROBLEM DEFINITION\n\n\nThe retrieval task considered in this work can be described as follows (see also Figure 1). Given a\nmulti-hop question _q_ and a large text corpus _C_, the retrieval module needs to retrieve a sequence of\npassages _Pseq_ : _{p_ 1 _, p_ 2 _, ..., pn}_ that provide _sufficient_ information for answering _q_ . Practically, the\nretriever returns the _k_ best-scoring sequence candidates, _{Pseq_ [1] _[,][ P]_ _seq_ [2] _[, ...,][ P]_ _seq_ _[k]_ _[}]_ [ (] _[k][ \u226a|C|]_ [), with the]\nhope that at least one of them has the desired qualities. _k_ should be small enough for downstream\nmodules to process in a reasonable time while maintaining adequate recall. In general, retrieval also\nneeds to be efficient enough to handle real-world corpora containing millions of documents.\n\n\n2.2 MULTI-HOP DENSE RETRIEVAL\n\n\n**Model** Based on the sequential nature of the multi-hop retrieval problem, our system solves it in an\niterative fashion. We model the probability of selecting a certain passage sequence as follows:\n\n\n\n_P_ ( _Pseq|q_ ) =\n\n\n\n_n_\n\n- _P_ ( _pt|q, p_ 1 _, ..., pt\u2212_ 1) _,_\n\n\n_t_ =1\n\n\n2\n\n\nPublished as a conference paper at ICLR 2021\n\n\nwhere for _t_ = 1, we only condition on the original question for retrieval. At each retrieval step, we\nconstruct a new query representation based on previous results and the retrieval is implemented as\nmaximum inner product search over the dense representations of the whole corpus:\n\n\nexp ( _\u27e8_ _**p**_ _t,_ _**q**_ _t\u27e9_ )\n_P_ ( _pt|q, p_ 1 _, ..., pt\u2212_ 1) =\n\n~~\ufffd~~ _p\u2208C_ [exp (] _[\u27e8]_ _**[p]**_ _[,]_ _**[ q]**_ _[t][\u27e9]_ [)] _[,]_",
      "<2-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 26,
    "question": "What is RAFT and how does it improve the performance of pre-trained Large Language Models on domain-specific RAG tasks?",
    "reference": "RAFT (Retrieval Augmented Fine Tuning) is a training recipe that improves the model's ability to answer questions in 'open-book' in-domain settings. In training RAFT, given a question and a set of retrieved documents, the model is trained to ignore distractor documents and cite verbatim the right sequence from relevant documents to help answer the question. This method consistently improves the model's performance across PubMed, HotpotQA, and Gorilla datasets when used in domain-specific RAG tasks.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al",
      "<2-hop>\n\nPreprint, Under Review\n\n## **RAFT: Adapting Language Model to Domain Specific RAG**\n\n\n\n**Tianjun Zhang** _[\u2217]_\nDepartment of Computer Science\nUC Berkeley\nBerkeley, CA 94720, USA\n```\n{tianjunz}@berkeley.edu\n\n```\n\n\n**Shishir G. Patil, Naman Jain, Sheng Shen**\nDepartment of Computer Science\nUC Berkeley\nBerkeley, CA 94720, USA\n```\n{shishirpatil,naman_jain,sheng.s}@berkeley.edu\n\n```\n\n\n**Matei Zaharia, Ion Stoica, Joseph E. Gonzalez**\nDepartment of Computer Science\nUC Berkeley\nBerkeley, CA 94720, USA\n```\n {matei,istoica,jegonzal}@berkeley.edu\n\n```\n\n**Abstract**\n\n\nPretraining Large Language Models (LLMs) on large corpora of textual\ndata is now a standard paradigm. When using these LLMs for many\ndownstream applications, it is common to additionally incorporate new information into the pretrained model either through RAG-based-prompting,\n\n    - r finetuning. However, the best methodology to incorporate information\nremains an open question. In this paper, we present Retrieval Augmented\nFine Tuning (RAFT), a training recipe which improves the model\u2019s ability\nto answer questions in \"open-book\" in-domain settings. In training RAFT,\ngiven a question, and a set of retrieved documents, we train the model to\nignore those documents that don\u2019t help in answering the question, which\nwe call, distractor documents. RAFT accomplishes this by citing verbatim\nthe right sequence from the relevant document to help answer the question.\nThis coupled with RAFT\u2019s chain-of-thought-style response helps improve\nthe model\u2019s ability to reason. In domain specific RAG, RAFT consistently\nimproves the model\u2019s performance across PubMed, HotpotQA, and Gorilla\ndatasets, presenting a post-training recipe to improve pre-trained LLMs to\nin-domain RAG.\n\n\n**1** **Introduction**\n\n\nTrained on vast quantities of public data, Large Language Models LLMs have achieved\nsignificant advances in a wide range of general knowledge reasoning tasks Brown et al.\n(2020); Wei et al. (2022). However, increasingly LLMs are being employed in specialized\ndomains"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 28,
    "question": "What challenges did Anil et al. face when developing their model and how did they overcome them?",
    "reference": "Anil et al. faced challenges in developing their model, particularly with complex multi-step reasoning. They overcame these challenges by proposing STEP-BACK PROMPTING, which grounds reasoning in abstractions to reduce errors in intermediate steps.",
    "contexts": [
      "<1-hop>\n\n as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al.,\n2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021).\n\n\nFigure 1: Strong Performance of STEP-BACK PROMPTING: our proposed Abstraction-and-Reasoning\nscheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge\nQA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning.\n\n\n_\u2217_ Equal Contribution\n\n\n1\n\n\nStep-Back Prompting Enables Reasoning Via Abstraction in Large Language Models\n\n\nDespite the great advancements, complex multi-step reasoning remains challenging for even the state\n- f-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification\nis a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such\nas Chain-of-Thought (Wei et al., 2022b) were introduced to produce a coherent series of intermediate\nreasoning steps to increase the success rate of following the right decoding path. Inspired by the\nfact that when faced with challenging tasks humans often step back and do abstractions to arrive at\nhigh-level principles to guide the process, we propose STEP-BACK PROMPTING to ground reasoning\n\n- n abstractions to reduce the chance of making errors in the intermediate reasoning steps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Illustration of STEP-BACK PROMPTING with two steps of Abstraction and Reasoning\nguided by concepts and principles. _Top_ : an example of MMLU high-school physics (Hendrycks et al.,\n2020) where the first principle of Ideal Gas Law is retrieved via abstraction. _Bottom_ : an example\nfrom TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the\nabstraction. _Left_ : PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought\nprompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning\nsteps (highlighted as red). _Right_ : PaLM-2L (Anil et al., 2023) successfully answers the question via"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 29,
    "question": "What is an example of a multi-hop reasoning task in MMLU high-school Physics?",
    "reference": "An example of a multi-hop reasoning task in MMLU high-school Physics is the original question about the pressure of an ideal gas when temperature and volume are changed. The correct answer requires applying the Ideal gas law twice, first to find the initial pressure and then to find the final pressure after the changes.",
    "contexts": [
      "<1-hop>\n\n by the friction\nbetween the object and the air molecules. The greater the surface area of the\n\n           - bject, the greater the air resistance. The tennis ball has a large surface area, so\nit experiences a lot of air resistance. This air resistance slows down the tennis\nball and causes the difference between the predicted velocity and the velocity\nmeasured by the photogate.\nTherefore, the correct answer is 0) The ball changes its shape while falling.\n\n\nTable 27: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\n**Reasoning Error** . In this case, the model was able to correctly identify air resistance is the cause of\nthe velocity difference, but made the error at the final reasoning step of deriving the right answer.\n\n\n31\n\n\nStep-Back Prompting Enables Reasoning Via Abstraction in Large Language Models\n\n\ndataset example\n\n\nMMLU-Physics **Original Question** : What happens to the pressure, P, of an ideal gas if\nthe temperature is increased by a factor of 2 and the volume is increased\nby a factor of 8 ?\n0) P decreases by a factor of 16.\n1) P decreases by a factor of 4.\n2) P decreases by a factor of 2.\n3) P increases by a factor of 4.\n**Original Answer [Incorrect]** : The correct answer is 0. The ideal gas\nlaw is PV = nRT. If the temperature is increased by a factor of 2 and the\nvolume is increased by a factor of 8, then the pressure will decrease by a\nfactor of 16.\n**Stepback Question** : What are the physics principles behind this\nquestion?\n**Principles** :\nIdeal gas law: PV = nRT, where P is the pressure, V is the volume, n is\nthe number of moles, R is the gas constant, and T is the temperature.\n**Final Answer** : Using the Principles of Ideal gas law, we can solve the\nproblem as following:\nStep 1: Apply Ideal gas law to find out the pressure of an ideal gas. The\nideal gas law states that PV = nRT, where P is the pressure, V is the\nvolume, n is the number of moles, R is the gas constant, and T is the\ntemperature.\n\n\nStep 2: Apply Ideal gas law to find out the pressure of",
      "<2-hop>\n\n as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al.,\n2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021).\n\n\nFigure 1: Strong Performance of STEP-BACK PROMPTING: our proposed Abstraction-and-Reasoning\nscheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge\nQA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning.\n\n\n_\u2217_ Equal Contribution\n\n\n1\n\n\nStep-Back Prompting Enables Reasoning Via Abstraction in Large Language Models\n\n\nDespite the great advancements, complex multi-step reasoning remains challenging for even the state\n- f-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification\nis a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such\nas Chain-of-Thought (Wei et al., 2022b) were introduced to produce a coherent series of intermediate\nreasoning steps to increase the success rate of following the right decoding path. Inspired by the\nfact that when faced with challenging tasks humans often step back and do abstractions to arrive at\nhigh-level principles to guide the process, we propose STEP-BACK PROMPTING to ground reasoning\n\n- n abstractions to reduce the chance of making errors in the intermediate reasoning steps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Illustration of STEP-BACK PROMPTING with two steps of Abstraction and Reasoning\nguided by concepts and principles. _Top_ : an example of MMLU high-school physics (Hendrycks et al.,\n2020) where the first principle of Ideal Gas Law is retrieved via abstraction. _Bottom_ : an example\nfrom TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the\nabstraction. _Left_ : PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought\nprompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning\nsteps (highlighted as red). _Right_ : PaLM-2L (Anil et al., 2023) successfully answers the question via"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 35,
    "question": "What specific research did Anil et al. contribute to in the field of large language models?",
    "reference": "Anil et al. contributed to the development of PaLM-2L, a large language model that successfully answers questions via step-back prompting and abstraction-and-reasoning schemes.",
    "contexts": [
      "<1-hop>\n\n as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al.,\n2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021).\n\n\nFigure 1: Strong Performance of STEP-BACK PROMPTING: our proposed Abstraction-and-Reasoning\nscheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge\nQA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning.\n\n\n_\u2217_ Equal Contribution\n\n\n1\n\n\nStep-Back Prompting Enables Reasoning Via Abstraction in Large Language Models\n\n\nDespite the great advancements, complex multi-step reasoning remains challenging for even the state\n- f-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification\nis a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such\nas Chain-of-Thought (Wei et al., 2022b) were introduced to produce a coherent series of intermediate\nreasoning steps to increase the success rate of following the right decoding path. Inspired by the\nfact that when faced with challenging tasks humans often step back and do abstractions to arrive at\nhigh-level principles to guide the process, we propose STEP-BACK PROMPTING to ground reasoning\n\n- n abstractions to reduce the chance of making errors in the intermediate reasoning steps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Illustration of STEP-BACK PROMPTING with two steps of Abstraction and Reasoning\nguided by concepts and principles. _Top_ : an example of MMLU high-school physics (Hendrycks et al.,\n2020) where the first principle of Ideal Gas Law is retrieved via abstraction. _Bottom_ : an example\nfrom TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the\nabstraction. _Left_ : PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought\nprompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning\nsteps (highlighted as red). _Right_ : PaLM-2L (Anil et al., 2023) successfully answers the question via"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 37,
    "question": "What contributions did Chunting Zhou make to the field of information retrieval?",
    "reference": "Chunting Zhou made significant contributions to the field of information retrieval through his work on summarization with pointer-generator networks and in-context pretraining. His research has helped advance language models by retrieving from trillions of tokens, improving their performance on various tasks.",
    "contexts": [
      "<1-hop>\n\nmight not be necessary. ELI5 (Fan et al., 2019)\nis a long-form QA dataset requiring in-depth answers to open-ended questions. Due to issues mentioned in Krishna et al. (2021) such as difficulties\n\n- f grounding generation in retrieval and evaluation, both single-time retrieval and FLARE did not\nprovide significant gains over not using retrieval.\nFrom an engineering perspective, interleaving generation and retrieval with a naive implementation\nincreases both overheads and the cost of generation.\nLMs need to be activated multiple times (once for\neach retrieval) and a caching-free implementation\nalso requires recomputing the previous activation\neach time after retrieval. This issue can be potentially alleviated with special architectural designs\nthat encode the retrieved documents _D_ _**q**_ _t_ and the\ninput/generation ( _**x**_ / _**y**_ _<t_ ) independently.\n\n\n**Acknowledgements**\n\n\nThis work was supported in part by a grant from\nthe Singapore Defence Science and Technology\nAgency and the IBM PhD Fellowship. We thank\nChunting Zhou, Amanda Bertsch, Uri Alon, Hiroaki Hayashi, Harsh Trivedi, Patrick Lewis, Timo\nSchick, Kaixin Ma, Shuyan Zhou, and Songwei Ge\nfor their insightful discussions and help with the\nexperiments.\n\n\n**References**\n\n\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\nCassirer, Andy Brock, Michela Paganini, Geoffrey\nIrving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\n[2022. Improving language models by retrieving from](https://proceedings.mlr.press/v162/borgeaud22a.html)\n[trillions of tokens. In](https://proceedings.mlr.press/v162/borgeaud22a.html) _International Conference on_\n_Machine Learning, ICML ",
      "<2-hop>\n\n Summarization with\npointer-generator networks. In _Proceedings of the 55th Annual Meeting of the Association for_\n_Computational Linguistics (Volume 1: Long Papers)_, pp. 1073\u20131083, Vancouver, Canada, July\n[2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1099. URL https:](https://www.aclweb.org/anthology/P17-1099)\n[//www.aclweb.org/anthology/P17-1099.](https://www.aclweb.org/anthology/P17-1099)\n\n\n14\n\n\nWeijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou, Margaret Li, Gergely Szilvasy, Rich James,\nXi Victoria Lin, Noah A. Smith, Luke Zettlemoyer, Scott Yih, and Mike Lewis. In-context\npretraining: Language modeling beyond document boundaries, 2024.\n\n\nAivin V. Solatorio. Gistembed: Guided in-sample selection of training negatives for text embedding\n[fine-tuning, 2024. URL https://arxiv.org/abs/2402.16829.](https://arxiv.org/abs/2402.16829)\n\n\nHongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen tau Yih,\nNoah A. Smith, Luke Zettlemoyer, and Tao Yu. One embedder, any task: Instruction-finetuned\ntext embeddings, 2023.\n\n\nMujeen Sung, Jungsoo Park, Jaewoo Kang, Danqi Chen, and Jinhyuk Lee. Optimizing test-time\nquery representations for dense retrieval, 2023.\n\n\nNandan Thakur, Nils Reimers, Andreas Ruckl\u00a8 e, Abhishek Srivastava, and Iryna Gurevych. Beir: A\u00b4\nheterogenous benchmark for zero-shot evaluation of information retrieval models, 2021.\n\n\nLiang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder,\nand Furu Wei. Simlm: Pre-training with representation bottleneck for dense passage retrieval,\n2023.\n\n\nLiang Wang, Nan Yang, Xiaolong Huang"
    ],
    "query_style": "",
    "query_length": ""
  },
  {
    "index": 39,
    "question": "What is the significance of LLaMA in the field of advanced models for information retrieval and understanding?",
    "reference": "LLaMA, or Large Language Model Meta AI, is a significant advancement in the field of advanced models for information retrieval and understanding. It has been used in various expansions, fine-tuning methods, and applications such as data chat, labeling, and self-knowledge SFT to improve the performance of other models like ChatGPT and GPT-4.",
    "contexts": [
      "<1-hop>\n\naca Data ChatGPT LLaMA Expansion SFT\nLion (Jiang et al., 2023b) IF Alpaca Cata ChatGPT LLaMA Labeling + Expansion + Feedback   BabyLlama (Timiryasov and Tastet, 2023) IF 10M-word BabyLM dataset GPT-2 + small LLaMA 58M-parameter LLaMA Feature D&S\nMiniLLM (Gu et al., 2024) IF Dolly Dataset GPT2 + OPT + LLaMA GPT2 + OPT + LLaMA Feature D&S\nSelf-Align (Sun et al., 2024b) IF Human-written Principles LLaMA LLaMA Expansion + Self-Knowledge SFT\nSelf-Rewarding (Yuan et al., 2024a) IF Human-written Samples LLaMA LLaMA Self-Knowledge SFT + RL\nSTaR (Zelikman et al., 2022) IF Arithmetic + CommonsenseQA + GSM8K GPT-J GPT-J Self-Knowledge SFT\nLlama-GPT4 (Peng et al., 2023a) IF Alpaca Dataset GPT4 LLaMA Labeling SFT\nReflection-Tuning (Li et al., 2023e) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nSelective Reflection-Tuning (Li et al., 2024d) IF Alpaca/WizardLM Dataset ChatGPT LLaMA Labeling SFT\nVicuna (Chiang et al., 2023) IF/MD Human Conversation ChatGPT + GPT4 LLaMA Labeling SFT\nKoala (Geng et al., 2023) IF/MD Human Conversation ChatGPT LLaMA Labeling SFT\nBaize (Xu et al., 2023b) IF/MD Quora + Stack Overflow ChatGPT LLaMA Expansion + Self-Knowledge SFT\nUltraChat (Ding et al., 2023b) IF/MD Wikidata + Text Material + C4 ChatGPT LLaMA Curation SFT\nOrca (Mukherjee et al., 2023) IF/TP FLAN-v2 ChatGPT + GPT4 LLaMA Labeling SFT\nOrca2 (Mitra et al"
    ],
    "query_style": "",
    "query_length": ""
  }
]