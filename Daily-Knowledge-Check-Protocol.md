# Daily Knowledge Check Protocol

**Purpose**: Test knowledge retention using spaced repetition based on forgetting curve
**Frequency**: End of each study day
**Duration**: 10-15 minutes

---

## Protocol

### Timing
- **When**: After completing the day's work (theory + implementation)
- **Before documentation**: Run knowledge check before creating quick reference sheets

### Question Distribution

**70% Today's Content** (Fresh learning):
- Core concepts from today's theory
- Implementation details from today's algorithm
- Key formulas or techniques learned

**30% Previous Content** (Spaced repetition):
- Selected from `data/knowledge-schedule.md` where `Next Review <= Current Date`
- Randomly choose, slightly prioritize items with larger overdue
- SM-2 algorithm automatically determines optimal review timing

### Question Types

1. **Conceptual** (40%):
   - "Explain X"
   - "When would you use X vs Y?"
   - "What are the limitations of X?"

2. **Implementation** (40%):
   - "Walk me through how to implement X"
   - "What's the time complexity and why?"
   - "What edge cases need handling?"

3. **Applied/Scenario** (20%):
   - "Given scenario X, which approach would you use?"
   - "How would you debug this issue?"
   - "What metric would you use for this problem?"

### Scoring

**Per Question**:
- âœ… **100%**: Correct, clear explanation, can elaborate
- ðŸŸ¡ **75%**: Mostly correct, minor gaps or unclear explanation
- ðŸŸ  **50%**: Partial understanding, significant gaps
- âŒ **25%**: Incorrect or "I don't know"

**Overall Score Interpretation**:
- **90-100%**: Excellent retention, ready to move forward
- **80-89%**: Good retention, minor review needed
- **70-79%**: Adequate, consider reviewing weak areas before moving on
- **<70%**: Significant gaps, should review before proceeding

### Feedback Format

For each answer:
1. âœ…/ðŸŸ¡/ðŸŸ /âŒ Score with brief assessment
2. What was correct
3. What needs improvement (if applicable)
4. Interview-ready answer (if significantly different)

At the end:
- Overall score percentage
- Summary of strong areas
- Summary of areas needing review
- Recommendation (proceed / review specific topics / review day)
- **Update `data/knowledge-schedule.md`** with SM-2 calculations (EF, interval, next review)

---

## SM-2 Spaced Repetition Workflow

**Implemented**: 2025-11-09 (Day 13)

**File**: `data/knowledge-schedule.md`

**Algorithm**: SuperMemo 2 (SM-2) for optimal review scheduling

### Overview

SM-2 automatically calculates when to review each topic based on:
- **EF (Easiness Factor)**: How easy the topic is for you (1.3-2.5+, default 2.5)
- **I (Interval)**: Days until next review
- **n**: Number of successful consecutive reviews
- **Performance history**: Your actual scores over time

### Daily Routine

#### Before Knowledge Check (2-3 min):

1. **Read schedule file**:
   ```bash
   Read data/knowledge-schedule.md
   ```

2. **Identify review items**:
   - Filter for items where `Next Review <= Current Date`
   - Select 3-5 items with oldest/lowest next_review dates
   - Example: If current date is 2025-11-10:
     ```
     llm_megatron: Next Review = 2025-11-10 âœ“ (due today)
     llm_tensor_parallel_comm: Next Review = 2025-11-10 âœ“ (due today)
     stats_4.3: Next Review = 2025-11-24 âœ— (not due yet)
     ```

3. **Generate questions (10 total)**:
   - **30% review**: 3 questions from items identified in step 2
   - **70% new**: 7 questions from today's new content
   - Maintain mix of conceptual, implementation, applied questions

#### After Knowledge Check (3-5 min):

For each reviewed item, calculate new values:

**Step 1: Map score to quality**

| Score Range | Quality (q) | SM-2 Rating | Interval Action |
|-------------|-------------|-------------|-----------------|
| â‰¤60% | 1 | Again (fail) | Reset to n=1, I=1 |
| 61-79% | 2 | Hard | Increase slowly |
| 80-90% | 3 | Good | Normal increase |
| >90% | 4 | Easy | Large increase |
| 100% | 5 | Perfect | Large increase |

**Step 2: Calculate new EF (Easiness Factor)**

```
EF' = EF + (0.1 - (5-q)Ã—(0.08 + (5-q)Ã—0.02))
EF' = max(1.3, EF')  # Floor at 1.3
```

**Step 3: Calculate new interval**

âš ï¸ **CRITICAL**: Update I **BEFORE** incrementing n (order matters!)

```
If q = 1 (failed):
    I = 1 day
    n = 1
Else if n = 0 (first review):
    I = 1 day
    n = 1
Else if n = 1:
    I = 6 days
    n = 2
Else (n >= 2):
    I = I_previous Ã— EF'
    n = n + 1
```

**Common mistake**: Setting I based on the NEW n value instead of OLD n value.
- âŒ Wrong: n=1â†’2, then set I=6Ã—EF (uses n=2)
- âœ… Correct: n=1, set I=6, then n=2 (uses n=1 to determine I)

**Step 4: Update schedule**

```
Last Review = Current Date
Next Review = Current Date + I days
Append score to Score History
Write updated row to data/knowledge-schedule.md
```

### Example Calculation

**Scenario**: Reviewed `stats_5.3` (Gambler's ruin) on 2025-11-10

**Old values**: EF=2.5, n=2, I=6, Last Review=2025-11-04

**User score**: 95% â†’ quality=4 (Easy)

**Calculations**:
```
Step 1: quality = 4 (Easy, since 95% > 90%)

Step 2: Calculate new EF
EF' = 2.5 + (0.1 - (5-4)Ã—(0.08 + (5-4)Ã—0.02))
    = 2.5 + (0.1 - 1Ã—(0.08 + 1Ã—0.02))
    = 2.5 + (0.1 - 0.10)
    = 2.5 + 0.0
    = 2.5 âœ“

Step 3: Calculate new interval
Since q=4 (passed) and n=2 (current):
    I' = 6 Ã— 2.5 = 15 days  (use OLD n=2 to determine formula)
    n' = 2 + 1 = 3          (increment after calculating I)

Step 4: Update values
Last Review = 2025-11-10
Next Review = 2025-11-10 + 15 = 2025-11-25
Score History = "75,95" (appended 95)
```

**Updated row in knowledge-schedule.md**:
```
| stats_5.3 | Gambler's ruin problem | Stats | 2.5 | 15 | 3 | 2025-11-10 | 2025-11-25 | 75,95 |
```

### Adding New Items Daily

**After each study and knowledge check session**, add newly studied topics to the schedule:

1. Identify 3-5 key concepts from today's study
  * Note: DO NOT lazily add one row per knowledge check question! Consider how to best organize the topics studied today. 
2. Create topic_id (format: `section_subtopic`, e.g., `llm_flash_attention`)
3. Consider the knowledge check as the first review and initialize with:
   ```
   EF = 2.5  # 2.5 is default; adjust according to initial knowledge check result
   n = 1 (not reviewed yet)
   I = 1
   Next Review: tomorrow
   Score History: knowledge check score
   ```
4. Add row to `data/knowledge-schedule.md`

### Special Cases

**Failure (score <=60%)**:
```
n = 1 (reset)
I = 1 day (review tomorrow)
EF decreases (formula applies)
```

**Perfect streak (multiple 100% scores)**:
```
EF gradually increases above 2.5
Intervals grow: 1â†’6â†’15â†’38â†’95 days (roughly 2.5Ã— each time)
```

**Overdue review**:
- If you miss a review date, just review when you can
- Calculate EF/interval normally based on performance
- SM-2 is forgiving of delays

### Tips

1. **Show your work**: Always calculate EF/I explicitly, don't skip steps
2. **Verify calculations**: User can spot-check math if uncertain
3. **Be consistent**: Use same quality mapping every time
4. **Don't game it**: Rate honestly - SM-2 works best with accurate feedback
5. **Track patterns**: If same item fails multiple times, need deeper study
6. **Add new items daily**: Keep schedule updated with newly studied concepts

---

## Benefits

1. **Spaced repetition**: Reviews content at optimal intervals before forgetting
2. **Early gap detection**: Identifies weak areas before they become problems
3. **Interview simulation**: Mimics interview question patterns
4. **Confidence building**: Proves retention and improvement over time
5. **Adjustment signal**: Low scores indicate need to slow down or review
6. **Automated scheduling**: SM-2 algorithm handles review timing optimization
7. **Adaptive learning**: EF values adjust based on actual performance history (easier items â†’ longer intervals, harder items â†’ more frequent review)

---

## Integration with Study Plan

### Daily Routine:
```
1. Theory refresh (if applicable)
2. Implementation practice
3. âœ… KNOWLEDGE CHECK (10-15 min) â† Includes SM-2 schedule updates
4. Create quick reference sheet
5. Update progress files
```

### Weekly Review:
- Compare knowledge check scores across week
- Identify persistent weak areas
- Adjust study focus for next week

---

## Sample Knowledge Check (Day 4 Example)

### Today's Content (70% - Regularization, Regression Metrics, K-Means):

**Q1**: Explain when to use L1 vs L2 regularization.

**Q2**: Why is Elastic Net better for correlated variables?

**Q3**: What are RÂ²'s main limitations and how do you address them?

**Q4**: Walk me through the K-Means algorithm steps.

**Q5**: Why are K-Means results unstable across runs?

**Q6**: What is inertia and how do you compute it?

**Q7**: Implement the K-Means assignment step in one line of NumPy.

### Previous Content (30% - Days 1-3):

**Q8** (Day 3): Explain bias correction in Adam optimizer. [1 day ago]

**Q9** (Day 3): When should you use Precision-Recall instead of AUC-ROC? [1 day ago]

**Q10** (Day 2): What's the gradient formula for logistic regression? [2 days ago]

**Total**: 10 questions, ~10-15 min

---

## Tracking Progress

### Knowledge Check Log:

| Day | Date | Overall Score | Strong Areas | Weak Areas | Action |
|-----|------|---------------|--------------|------------|--------|
| 1 | 2025-10-27 | N/A | - | Assessment day | - |
| 2 | 2025-10-29 | N/A | - | - | - |
| 3 | 2025-10-30 | 88% (B+) | Implementation, NumPy, bias correction | Explaining "why" (Adam, Precision-Recall) | Polish reasoning |
| 4 | 2025-10-31 | 95% (A) | Regularization, metrics, K-Means algorithm, retention | Inertia code formula (70%), K-Means "keep best" detail | Review inertia calculation |
| 5 | 2025-11-01 | **98.5% (A+)** | Boosting (perfect), parametric/non-parametric, **inertia resolved (95%)** | None identified | Continue momentum |
| 6 | 2025-11-03 | 66.5% | Gap analysis complete (189 questions) | LLM systems (30%), statistics (65%), RAG (30%) | Week 2 focus areas identified |
| 7 | 2025-11-04 | N/A | Topic coverage check (82% dunno) | - | Week 2 Day 1 begins |
| 8 | 2025-11-04 | **80.8% (B+)** | Megatron-LM basics (77%), Review retention (100%) | ZeRO Stage 3 (0%), ZeRO memory reductions (40%), Tensor parallel comm (70%) | Read ZeRO Section 5, reinforce Stage 3 |
| 9 | 2025-11-05 | **98% (A+)** | Backward pass (97.9%), ZeRO Stage 3 resolved (95%), f/g operators (100%), Review (95%) | Minor terminology precision | Continue Day 3-4 topics |
| 10 | 2025-11-06 | **99.0% (A+)** | Hardware bottlenecks (99.3%), Communication scaling (perfect), Review (98.3%), **User caught 3 errors!** | None - all concepts strong | Day 4: Inference optimization |
| 11 | 2025-11-07 | **97.5% (A+)** | All 6 inference techniques (97.9%), Memory formulas (100%), Trade-off analysis (perfect), Review (96.7%) | Speculative decoding batch reasoning (75%, clarified) | Continue Week 2 momentum |
| 12 | 2025-11-08 | **99.6% (A+)** | **Perfect calculations (100%)** - Parameters (GPT-2/3), Memory (7B/10B models), Batch size optimization, Chinchilla law, Review (97.7%) | None - minor rounding in KV-cache (820 vs 800 KB) | **Week 2 LLM Systems COMPLETE: 83% readiness** |
| 13 | 2025-11-09 | **99.5% (A+)** | **Regression diagnostics (99.3%)** - DW, BP, SW, VIF tests perfect, Covariance vs correlation (100%), Review (100%) | None - all topics >95%, caught error in Q6 (impossible correlation value) | Statistics Day 1: Diagnostics mastered |
| 14 | 2025-11-10 | **86.5% (B+/A-)** | MLE derivations (100%, 100%, 85%), Chi-square test (100%), Normal dist calculations (90%), Covariance review (100%) | T-test assumptions (70%), DW interpretation (75%), AUC for imbalanced data (70%) | Statistics Day 2: Strong fundamentals, minor gaps in test assumptions |
| 15 | 2025-11-11 | **92.0% (A-)** | Regularization/priors (90%), A/B testing (100%, 95%), Distributions (75%, 90%, 100%), CLT/LLN (70%), Review perfect (100%, 100%, 100%) | Binomial variance formula (75%), CLT concrete examples (70%) | Statistics Day 3: Strong fundamentals, perfect review retention |
| 16 | 2025-11-12 | **92.5% (A-)** | PyTorch basics (BCELoss 100%, training loop 95%, no_grad 95%, parameters 95%, backward 90%), Review excellent (KNN 95%, Boosting 100%, MLE 100%) | Training loop order (85% - both work), FSDP sync (70%), FSDP prefetch (60%) | PyTorch Day 1: Strong fundamentals, FSDP concepts need exposure |
| 17 | 2025-11-13 | **95.1% (A)** | Kafka (96.25% - consumer groups, ISR, acks), Feature Stores (93.3% - online/offline, point-in-time 100%), Review excellent (95% - parametric/non-parametric 100%, KV-cache 95%, quantization 85%) | Training-serving skew elaboration (85%), GPTQ vs AWQ usage (85% - research-level) | ML Infrastructure Day 1: Excellent first-day absorption, point-in-time correctness perfect |
| 18 | 2025-11-14 | **95.5% (A+)** | Airflow (97.5% - executors 100%, catchup 100%, idempotency 95%), Feature Store transformations (98.3% - batch vs streaming perfect), Review mixed (90% - Kafka 100%, Feature Store 100%, backward pass 70%) | Backward pass all-reduce locations (70% - concatenate vs sum confusion) | ML Infrastructure Day 2: Outstanding new content (97.9%), one conceptual gap in review |
| 19 | 2025-11-15 | **89.5% (B+/A-)** | Docker (image/container 95%, build/run 95%), Kubernetes (HPA 95%, resources 90%), Review perfect (regression 95%, bandwidth 100%, PyTorch 100%) | Multi-stage builds ML use case (70%), K8s Deployment definition (75%), GPU specifics (80%) | ML Infrastructure Day 3: Strong fundamentals (85.7%), perfect review retention (98.3%) |
| 20 | 2025-11-16 | **91% (A-/A)** | Data pipelines (100%), Bias handling (100%), A/B testing (100%), Two-tower (90%), Throughput calc (85% - revised), Review excellent (Airflow 100%, continuous batching 100%, VIF 85%) | GPU scaling calculation (50% - missed given numbers) | System Design Day 1: Mock interview 78/100 (B+), perfect conceptual understanding, correctly understood 1K predictions = 1 request |
| 21 | 2025-11-17 | **97.0% (A+)** | Cost analysis mastery, Feature engineering (20 features), Dynamic batching, Sliding windows, Manual review volumes, Class imbalance strategies, Review excellent (Kafka 100%, Docker 100%, HPA 100%) | Dynamic batching as first optimization (75% - clarified) | Week 3 complete: System design 85-90% ready |
| 22 | 2025-11-18 | **96.0% (A+)** | RAG fundamentals (98.9% - RRF, SPLADE, DPR, reranking, ColBERT, MMR), Review retention (88.3% - MLE 90%, Covariance 75%, Throughput 100%) | RRF ranking interpretation (90%), Covariance formulas missing (75%) | Week 4 Day 1 complete: Advanced RAG Day 1 mastery, 11 topics studied (7 new + 4 consolidated) |

**Progress Trend**: Week 2-4 sustained excellence ðŸš€
- Day 3â†’5: +10.5% improvement over Week 1
- Day 5â†’8: Maintained momentum through gap analysis + topic check
- Day 8â†’9: +17.2% improvement (80.8% â†’ 98%) - Outstanding!
- Day 9â†’10: +1.0% improvement (98% â†’ 99%) - Sustained mastery level
- Day 10â†’11: -1.5% (99.0% â†’ 97.5%) - Still A+ range, excellent retention
- Day 11â†’12: +2.1% improvement (97.5% â†’ 99.6%) - **Perfect calculations**
- Day 12â†’13: -0.1% (99.6% â†’ 99.5%) - **Sustained mastery level (99%+ range)**
- Day 13â†’14: -13.0% (99.5% â†’ 86.5%) - Expected dip for new complex material (MLE, hypothesis testing)
- Day 14â†’15: +5.5% improvement (86.5% â†’ 92.0%) - Recovery to A- range
- Day 15â†’16: +0.5% improvement (92.0% â†’ 92.5%) - Steady A- range
- Day 16â†’17: +2.6% improvement (92.5% â†’ 95.1%) - ML Infrastructure day 1
- Day 17â†’18: +0.4% improvement (95.1% â†’ 95.5%) - Sustained A+ range
- Day 18â†’19: -6.0% (95.5% â†’ 89.5%) - Expected dip for new infrastructure topics (Docker/K8s)
- Day 19â†’20: +1.5% (89.5% â†’ 91%) - Recovery to A-/A range (revised after throughput calc correction)
- Day 20â†’21: +6.0% (91% â†’ 97%) - Outstanding recovery to A+ range
- Day 21â†’22: -1.0% (97% â†’ 96%) - Minor dip, still A+ range, excellent RAG absorption
- **Week 2 Days 1-5 average**: 92% across Days 8-12 (LLM Systems)
- **Week 2 Days 6-7 (Statistics)**: Average 93% (Day 13: 99.5%, Day 14: 86.5%)
- **Week 3 Days 1-5 average**: 93.5% across Days 15-19 (Statistics completion + ML Infrastructure deep dive)
- **Week 3 Days 6-7 (System Design)**: Day 20 91% + 78/100 mock, Day 21 97% - strong system design practice
- **ML Infrastructure (Day 17-18)**: Averaging 95.3% on brand new territory - excellent absorption
- **Day 10 highlight**: User caught 3 approximations/errors (bubble time formula, ranking, TP scaling)
- **Day 11 highlight**: User caught 2 major errors (communication volume per-device, speculative decoding ragged tensor problem)
- **Day 12 highlight**: Perfect calculations, caught blog post imprecision on PP activation memory, clarified gradient memory storage
- **Day 13 highlight**: Perfect diagnostics understanding, caught impossible correlation in test question (r=2)
- **Day 14 highlight**: Perfect MLE derivations (100%), identified ÏƒÌ‚Â² vs ÏƒÌ‚ distinction, user scored conservatively on ROC/AUC (70%)
- **Day 15 highlight**: Perfect review retention (100% on all 3 overdue items), Megatron 77%â†’100%, Precision-Recall 88-92%â†’100%
- **Day 16 highlight**: Removed duplicate topic (llm_tensor_parallel_comm), excellent PyTorch fundamentals (87.9%), perfect review retention (98.3%)
- **Day 17-19 highlight**: ML Infrastructure gap closure 0%â†’65% in 3 days (Kafka, Feature Stores, Airflow, Docker, K8s)
- **Day 20 highlight**: First system design practice - mock interview 78/100 (B+), perfect data pipeline/bias understanding (100%), **user caught throughput calculation error** (1K predictions = 1 request, not 10K QPS!), critical gap: reading given numbers in problem statements (50%)
- **Day 21 highlight**: Fraud detection system design - 97% (A+), perfect review retention (100%), **user caught 4 major errors in Day 21 reference doc**: messy dynamic batching calcs, missing batch time explanation, manual review threshold inconsistency, WRONG class imbalance math (downsampling + weights DON'T cancel out!)
- **Day 22 highlight**: Advanced RAG Day 1 - 96% (A+), nearly perfect new content (98.9%), excellent consolidation of 4 "unsure" topics, RRF formula mastered, ColBERT storage trade-off understood
- Review retention: 95% average (Day 21 review: 100% - Kafka, Docker, HPA; Day 22 review: 88.3% - MLE, Covariance, Throughput)

---

## Weak Items Tracking

**Purpose**: Track items needing additional review until mastered

**SM-2 Integration**: With SM-2 implemented (Day 13+), weak items are automatically tracked via EF (Easiness Factor):
- **EF < 1.8**: Struggling items (review every 1-3 days until improved)
- **EF 1.8-2.2**: Moderate difficulty (review every 3-8 days)
- **EF > 2.5**: Strong items (review every 12+ days)

Items with low scores (<60%) automatically reset to n=1, I=1 (review tomorrow). No manual tracking needed.

**Historical Weak Items** (pre-SM-2, for reference):

**Resolved Items** (scored 90%+ on retest):
- âœ… **Inertia computation** (Day 4: 70% â†’ Day 5: 95%) - Resolved in 1 day!
- âœ… **ZeRO Stage 3 all-gather pattern** (Day 8: 0% â†’ Day 9: 100%) - Resolved in 1 day!
- âœ… **ZeRO memory reductions** (Day 8: 40% â†’ Day 9: 95%) - Resolved in 1 day! (Corrected scoring: "up to 4Ã—/8Ã—" was correct)
- âœ… **Tensor parallel all-reduce locations** (Day 8: 70% â†’ Day 9: 100%) - Resolved in 1 day!
