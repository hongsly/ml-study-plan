# ML Engineer Interview Prep - 12 Week Study Plan

**Timeline**: 2-3 months
**Time Commitment**: 5-10 hours/week
**Total Hours**: 60-120 hours
**Target Role**: ML Engineer
**Background**: Senior SWE with production ML experience + ML certifications (knowledge faded, needs refresh)

---

## Overview

This plan is optimized for **passing ML Engineer interviews** at top tech companies. Focus is on:
- **Refreshing implementation skills** (you know theory, need practice coding)
- Building interview-ready portfolio projects
- Mastering ML system design
- Sharpening coding and theory questions

**Adjustment from generic plan**: Since you've completed certifications, you'll move faster through lectures and spend MORE time on hands-on coding and projects.

---

## Phase 1: Foundations Refresh (Weeks 1-4)

**Goal**: Refresh ML fundamentals and build confidence through hands-on projects
**Time**: 20-40 hours total

### Week 1: Assessment + Fast.AI Kickstart (CUSTOMIZED FOR YOU)

**NEW: Assessment Phase (Day 1-2, 2-3 hours)**:

Since you've completed certifications but feel rusty, start with a reality check:

**Day 1 - Coding Assessment (COMPLETED)** ‚úÖ:
- [X] Implemented Linear Regression from scratch (~1 hour)
  - Correct implementation with minor issues (forgot averaging in loss)
  - Good vectorization and code structure
- [X] Implemented Logistic Regression from scratch (~1 hour)
  - Correct implementation with gradient dimension bug
  - Had to look up cross-entropy formula
  - Struggled with derivative computation
- [X] Identified rust areas:
  - üî¥ **Gradient derivations** (HIGH priority) - took most time
  - üü° Matrix dimensions (medium) - small bugs with X.T @ error
  - üü° Loss function details (medium) - forgot averaging
  - ‚úÖ Numpy operations (good)
  - ‚úÖ Algorithm structure (good)

**Day 1 Key Learnings**:
- Implementation time: 1 hour each (target: 20-25 min for interviews)
- Need to memorize common gradient formulas
- Foundation is solid, just need to build speed through practice

---

**Day 2 - Speed Practice (REVISED for 1-2 hours)**:

**Goal**: Prove you can implement faster with muscle memory

**Session 1 - Re-implement Logistic Regression (45-60 min)** ‚úÖ **COMPLETED**:
- [X] Implement Logistic Regression again from scratch
  - Target: 30-40 minutes ‚Üí **Actual: 15 minutes!** üéâ
  - Didn't look at yesterday's code ‚úÖ
  - Got gradient right first time: `X.T @ (yP - y) / n` ‚úÖ
  - Remembered to average the loss: `loss / n` ‚úÖ
  - Added numerical stability: `np.clip(yP, epsilon, 1-epsilon)` ‚úÖ
- [X] Compare with yesterday's implementation
  - **4x speed improvement**: 60 min ‚Üí 15 min ‚úÖ
  - Gradient correct this time ‚úÖ
  - Loss function has averaging ‚úÖ
  - **Beat sklearn accuracy**: 98.2% vs 97.4% ‚úÖ

**Session 2 - Quick Reference (30-45 min if time)**:
- [X] Create personal gradient cheat sheet (see Gradient-Formulas-Cheatsheet.md)
- [X] Quick skim of ML-Coding-Questions.md
- [X] List 3 algorithms to practice this week: K-NN, K-Means, (Optional: Decision Tree)

**Day 2 Success Criteria** ‚úÖ **ALL ACHIEVED**:
- ‚úÖ Implemented LogReg in **15 min** (exceeded 30-40 min target!)
- ‚úÖ Got gradient formula right without looking it up
- ‚úÖ Built muscle memory for the pattern
- ‚úÖ **Bonus**: Achieved 98.2% accuracy, beat sklearn

**Day 2 Results Summary** (2025-10-29):
- ‚è±Ô∏è **Time**: 15 minutes (beat target by 2x)
- üéØ **Accuracy**: 98.2% (beat sklearn's 97.4%)
- üìà **Speed improvement**: 4x faster than Day 1
- üíØ **All formulas correct** on first try
- ‚úÖ **Interview-ready**: Well within 20-25 min target

**Confidence Level Updated**: **HIGH** - Ready to move forward
- Day 2 proved rust was superficial
- Muscle memory returns quickly with practice
- Can accelerate through remaining material

---

**Day 3-7**: Ready to proceed as planned

---

**Day 3 - Hybrid Approach (2 hours)** ‚úÖ **Session 1 COMPLETE**:

**Session 1: Theory Refresh** (1 hour) ‚úÖ:
- [X] Reviewed ML-Theory-Questions.md - identified gaps
- [X] Watched optimization videos (Momentum, RMSprop, Adam) - 30 min
- [X] Watched AUC-ROC video (StatQuest) - 15 min
- [X] Watched Attention mechanism video (StatQuest) - 15 min
- [X] Created Day3-Quick-Reference.md with consolidated notes

**Key learnings**:
- Adam optimizer: Combines momentum + RMSprop, bias correction for early iterations
- AUC-ROC: TPR vs FPR, use for moderate imbalance, not extreme
- Attention/Transformers: Q-K-V mechanism, BERT vs GPT parallel processing
- Connected to production ML experience (transormers, LLMs)

**Theory Gaps Identified** üü°:
- Refreshed: Optimizers (Adam, momentum), AUC-ROC, Attention/Transformers ‚úÖ
- Still need: Boosting, Elastic Net, kernel trick, batch norm details (lower priority)
- Can skip: Reinforcement learning (unless RL-specific role)

**Session 2: K-NN Implementation** (50 min) ‚úÖ **COMPLETED**:
- [X] Implemented K-Nearest Neighbors from scratch
- [X] Tested on iris dataset
- [X] Algorithm correct, clean code structure
- [X] Used efficient NumPy operations (argpartition, unique)
- [X] Learned NumPy broadcasting for vectorization

**Day 3 Results Summary** (2025-10-30):
- ‚è±Ô∏è **Theory**: ~1 hour (optimizers, metrics, attention/transformers)
- ‚è±Ô∏è **Implementation**: ~50 min (K-NN with interruptions)
- üí° **Key learnings**: Adam bias correction, AUC-ROC vs Precision-Recall, Q-K-V attention
- üìù **Created**: Day3-Quick-Reference.md with interview-ready answers
- üîß **Implementation**: Correct K-NN, good NumPy skills, Python scope practice needed

---

**Day 4 - Hybrid: Theory + K-Means (2 hours)** ‚úÖ **COMPLETED**:

**Session 1: Theory Refresh** (45 min) ‚úÖ:
- [X] Regularization (L1/L2, Elastic Net) - 30 min
  - Watched StatQuest videos (Ridge, Lasso, Elastic Net)
  - L1 (Lasso): Sparse weights (exact 0), feature selection
  - L2 (Ridge): Asymptotic to 0, keeps all features
  - Elastic Net: Combines L1 + L2, better for correlated variables
  - Understanding: Why Elastic Net groups correlated features
- [X] Regression metrics - 15 min (reading, not videos)
  - MAE: Robust to outliers, equal penalty
  - RMSE: Penalizes large errors, same units as target
  - R¬≤: Variance explained, range (-‚àû, 1]
  - R¬≤ limitations: Always increases with features ‚Üí use Adjusted R¬≤
- [X] Batch normalization - Deferred to Week 2-3 (DL-specific)

**Session 2: K-Means Implementation** (~40 min) ‚úÖ:
- [X] Implemented K-Means clustering from scratch
  - Random centroid initialization with `np.random.choice`
  - Assignment step using `np.argmin(distances, axis=1)`
  - Update step with `X[labels == k].mean(axis=0)`
  - Convergence check with `np.allclose`
  - Empty cluster handling (reinitialize randomly)
- [X] Tested on synthetic blob data
- [X] Compared with sklearn.cluster.KMeans
  - **Inertia match**: 212.006 (exact match!)
  - Centroids match (different label order, expected)

**Day 4 Results Summary** (2025-10-31):
- ‚è±Ô∏è **Theory**: ~45 min (regularization 30 min + regression metrics 15 min)
- ‚è±Ô∏è **Implementation**: ~40 min (K-Means)
- üí° **Key learnings**:
  - Regularization: L1 vs L2 vs Elastic Net tradeoffs
  - Elastic Net better for correlated variables (grouping effect)
  - R¬≤ always increases with features ‚Üí need Adjusted R¬≤
  - K-Means sensitive to initialization (local minimum problem)
  - Python array assignment gotcha: need `.copy()`
- üìù **Created**: Day4-Quick-Reference.md with regularization, metrics, K-Means
- üîß **Implementation**: Correct K-Means, matches sklearn exactly, efficient broadcasting

**Knowledge Check Results** (88% - B+/A- level):
- Implementation (LogReg, K-NN): 95% ‚úÖ
- Algorithm complexity: 100% ‚úÖ
- Optimizers: 80% üü° (minor detail on adaptive LR)
- Bias correction: 95% ‚úÖ
- Evaluation metrics: 75% üü° (reasoning clarity)
- Transformers: 85% ‚úÖ (minor terminology)
- Attention: 90% ‚úÖ
- NumPy: 100% ‚úÖ

**Overall Progress**: Excellent retention, interview-ready on implementation, needs minor polish on explaining "why"

**Success Criteria**: ‚úÖ All met
- ‚úÖ Can explain when to use L1 vs L2 regularization
- ‚úÖ Can explain difference between MAE and RMSE and R¬≤ limitations
- ‚úÖ K-Means converges to stable clusters
- ‚úÖ Results match sklearn exactly (inertia 212.006)

---

**Day 5 - Theory Only: Boosting + Parametric/Non-parametric (<1 hour)** ‚úÖ **COMPLETED**:

**Context**: Weekend day with kids, limited time (~45 min)

**Session: Theory Refresh** (45 min) ‚úÖ:
- [X] AdaBoost (StatQuest) - 20 min
  - Stumps with "amount of say"
  - Sample weight adjustment
  - Formula: `0.5 * log((1-error)/error)`
- [X] Gradient Boost Part 1 (StatQuest) - 15 min
  - Builds trees on residuals
  - Learning rate scaling
  - Small trees (8-32 leaves)
- [X] Parametric vs Non-parametric - 5 min (reading)
  - Fixed parameters vs grows with data
  - Examples: LogReg/NN (parametric), K-NN/Decision Tree (non-parametric)
- [X] Knowledge check - 10 min

**Day 5 Results Summary** (2025-11-01):
- ‚è±Ô∏è **Total time**: ~45 min (theory only, efficient weekend session)
- üí° **Key learnings**:
  - Boosting: Sequential weak learners, focuses on errors
  - AdaBoost: Reweights samples, amount of say
  - Gradient Boost: Predicts residuals, learning rate
  - Parametric: Fixed parameters (LogReg, NN)
  - Non-parametric: Grows with data (K-NN, Decision Tree)
- üìù **Created**: Day5-Quick-Reference.md with boosting + parametric/non-parametric
- üìä **Knowledge Check: 98.5% (A+)** - Outstanding retention despite limited time
  - Perfect boosting understanding (99.3%)
  - Inertia resolved: 70% ‚Üí 95% in 1 day! üéâ
  - Overall trend: +10.5% over 3 days (88% ‚Üí 98.5%)

**Success Criteria**: ‚úÖ All met
- ‚úÖ Can explain boosting vs bagging
- ‚úÖ Can explain AdaBoost algorithm with formulas
- ‚úÖ Can explain Gradient Boost concept
- ‚úÖ Can distinguish parametric vs non-parametric with examples

---

**Day 6-7: Rapid Gap Analysis (2025-11-03)** ‚úÖ **COMPLETED**:

**Strategic Pivot**: Instead of continuing algorithm implementations, conducted **comprehensive gap assessment** across all 189 ML interview questions.

**Results**:
- ‚úÖ All 189 questions assessed in ~190 minutes
- ‚úÖ Overall score: 66.5% (75% interview readiness)
- ‚úÖ Identified critical gaps: LLM systems optimization (30%), statistical testing (0-30%), advanced RAG (0-30%)
- ‚úÖ Validated strengths: ML fundamentals (95%), classical ML (90%), deep learning (85%), NLP/transformers (85%)
- ‚úÖ Created detailed documentation: Day6-Gap-Analysis.md + Day6-Gap-Analysis-Detailed.md

**Key Findings**:
- **Performance Distribution**: 55% strong (80-100%), 39% rusty (40-79%), 6% major gaps (0-39%)
- **Critical Gap**: LLM systems optimization - limited experience with distributed training and GPU optimization
- **Strategic Insight**: Gap pattern aligns with career trajectory (model building ‚Üí LLM integration)

**Week 2 Plan Revised**: Focus on closing critical gaps
- Day 1-2: LLM systems optimization (Megatron-LM, ZeRO papers, NVIDIA GTC talks)
- Day 3: Statistical testing (t-tests, regression assumptions)
- Day 4-5: Advanced RAG (FiD architecture, hybrid retrieval)
- Day 6-7: ML evaluation & problem reframing

See **Day6-Gap-Analysis.md** for complete details and study recommendations.

---

**Learning - Adjusted Approach** (Updated based on Day 3 decisions):

**Fast.AI Decision**: ‚è≠Ô∏è **Skipped for now**
- Reason: Strong foundation
- Better use of time: Targeted theory refresh + algorithm implementation
- May revisit: Week 4+ if time permits, or specific lessons at 2x speed

**Deployment Learning**: üìÖ **Deferred to Week 2-3**
- Will learn Gradio/HuggingFace Spaces when building projects (~30 min)
- Modern tooling landscape (Docker/K8s/Cloud ML) - 2-3 hours in Week 2

**Hands-on - MORE TIME HERE (Day 5-7, 4-5 hours)**:

This is where you need the most practice:
- [ ] Set up development environment (Jupyter, Python, PyTorch/TensorFlow)
- [ ] Complete Fast.AI Chapter 1 exercises (don't skip!)
- [ ] Implement 2-3 algorithms from scratch:
  - K-Nearest Neighbors (easy warmup)
  - Decision Tree or K-Means (medium)
  - Neural Network with backprop (hard, optional)
- [ ] Start Project 1: Image classification
  - Use transfer learning (ResNet or EfficientNet)
  - Focus on clean code, not just accuracy

**Week 1 Goals**:
- ‚úÖ Know exactly where you're rusty
- ‚úÖ Refresh hands-on coding muscle memory
- ‚úÖ Have working image classifier started
- ‚úÖ Confidence boost from implementing algorithms

**Resources**:
- Fast.AI Course: https://course.fast.ai/
- ML-Coding-Questions.md (your reference for algorithms to implement)
- Stanford CS229: https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU (reference only)
- Kaggle Datasets: https://www.kaggle.com/datasets

**Adjustment Tip**: If Week 1 feels too easy (you remember more than expected), skip ahead. If it feels too hard, slow down and watch more lectures.

---

## üîÑ **REVISED PLAN BASED ON DAY 6-7 GAP ANALYSIS**

**Context**: Day 6-7 gap analysis (189 questions) revealed:
- ‚úÖ Strong foundation: ML fundamentals (95%), classical ML (90%), deep learning (85%), NLP/transformers (85%)
- ‚ùå Critical gaps: LLM systems optimization (30%), statistical testing (65%), advanced RAG (30%)
- üéØ Overall readiness: 75% (B+) - ready for mid-level roles, need gap closure for senior roles

**Strategic adjustment**: **Prioritize closing critical gaps** over building projects in Weeks 2-4, then reassess.

---

### Week 2: LLM Systems Deep Dive + Statistical Testing

**Goal**: Achieve interview-ready level (60-70%) in LLM Systems Optimization, close statistical testing gaps

**Context**: Day 8 topic coverage check revealed 82% dunno (62/76 topics) in LLM Systems ‚Üí This is foundational learning, not gap closure. Adjusted timeline from 2 days to 5 days with focused 24 high-impact topics.

**NEW PROTOCOL**: **Topic Coverage Check** ‚úÖ **COMPLETED (Day 8)**
- ‚úÖ Comprehensive 76-subtopic inventory created (Week2-LLM-Systems-Topic-Check.md)
- ‚úÖ Self-assessment completed: 0 Know, 14 Unsure (18%), 62 Dunno (82%)
- ‚úÖ Priority topics identified: 24 high-impact topics selected for interview readiness

**Strategy**: Breadth over depth, focus on interview-frequent topics, 3 key papers

---

**Day 1-2: Training Systems Fundamentals (4 hours)** üîÑ **IN PROGRESS**

**Topics** (8 topics):
1. Data parallelism - gradient synchronization
2. Model parallelism - layer splitting
3. Tensor parallelism - attention head splitting
4. **Strong scaling** (Gap Q182)
5. Activation checkpointing
6. ZeRO optimization (Stages 1/2/3)
7. **Memory sharding** (Gap Q184)
8. Mixed precision training

---

**Day 1 Progress** ‚úÖ **COMPLETED (2025-11-04)**:

**Study**:
- [X] Read: Megatron-LM paper (Sections 1-3, focus on tensor parallelism) - 1.5 hours
  - URL: https://arxiv.org/abs/1909.08053
  - ‚úÖ Tensor parallelism for attention heads, FFN layers
  - ‚úÖ Model vs data parallelism trade-offs
  - ‚úÖ Cross-node communication challenges
- [X] Read: ZeRO paper (Sections 1-4, superficial) - 1 hour
  - URL: https://arxiv.org/abs/1910.02054 or local: references/ZeRO_Memory Optimizations Toward Training Trillion Parameter Model 1910.02054v3.pdf
  - ‚úÖ ZeRO-DP three stages overview (Pos/Pos+g/Pos+g+p)
  - ‚úÖ Memory reductions: 4√ó, 8√ó, Nd√ó
  - üîÑ Section 5 technical details - **DEFERRED TO DAY 2**

**Knowledge Check**:
- [X] Completed: 10.5/13 = **80.8%** (B+)
  - Megatron-LM: 77% - Interview-ready for basic questions
  - ZeRO: 47% - Needs Section 5 study
  - Review: 100% - Excellent Week 1 retention

**Topics Status**:
- ‚úÖ Data parallelism, model parallelism, tensor parallelism - Understood
- üü° Strong scaling, activation checkpointing, memory sharding - Partial
- ‚úÖ ZeRO optimization Stages 1/2/3 - Conceptual understanding
- üü° Mixed precision training - Mentioned, needs depth

---

**Day 2 Progress** ‚úÖ **COMPLETED (2025-11-05)**:

**Study**:
- [X] Read: ZeRO paper Sections 1-5 and 7
  - Clarified: Reduce-scatter vs scatter-reduce terminology
  - Understood: All-gather in forward AND backward for Pos+g+p
  - Learned: Communication breakdown (1Œ® forward + 2Œ® backward = 3Œ® total)
- [X] Read: HuggingFace guide - Partial (PP+DP diagram, 3D parallelism benefits)
  - Key learning: PP staggers DP communication ‚Üí reduces network congestion
- [X] Create: 1-page cheat sheet - Week2-Day1-2-Cheatsheet.md
  - Includes: 3 parallelism strategies, Megatron-LM patterns, ZeRO 3 stages, ZeRO-R, 3D parallelism, interview Q&A, formulas, pitfalls, real-world examples
  - **Added**: Complete backward pass section (f/g operators, 4 all-reduces per layer)

**Practice**:
- [X] Derive: Backprop gradients for column-parallel (W1) and row-parallel (W2) layers
  - Result: 95-100% understanding, identified all-reduce locations and reasoning
- [X] Trace: Complete MLP block gradient flow (forward + backward)
  - Result: 98%, identified all 4 all-reduces (2 forward + 2 backward)
- [X] Calculate: Strong scaling example (3D parallelism memory/communication)
  - Result: 95%, wrote equations correctly (no numerical calc due to time)

**Knowledge Check** (15 min):
- [X] 70% Day 2 content + 30% Review
- [X] Score: **98% (9.8/10)** - A+
  - Day 9 content: 97.9%
  - Review: 95% (Day 8 weak items resolved, Week 1 retention perfect)

**Day 1-2 Final Status**: ‚úÖ **EXCEEDED TARGETS**
- ‚úÖ 8/8 topics at interview-ready level (can explain all in 2-3 min)
- ‚úÖ ZeRO understanding: 47% ‚Üí 95%+ (far exceeded 75% target)
- ‚úÖ Overall: 70% ‚Üí **85%+** (exceeded 80% target)
- ‚úÖ **Weak items**: 3/3 Day 8 gaps resolved in 1 day

---

**Day 3: Parallelism Strategies & Hardware** ‚úÖ **COMPLETED (2025-11-06)**

**Topics** (6 topics):
9. FSDP (Fully Sharded Data Parallel) - how it works
10. **Communication costs** - FSDP vs model parallelism (Gap Q185)
11. Gradient accumulation (via microbatches in PP)
12. Memory hierarchy (HBM, L2, L1, registers)
13. **Arithmetic intensity** (Gap Q183)
14. **Interconnect bandwidth** (Gap Q185)

**Study Completed**:
- [X] Read: Tim Dettmers "GPU Memory Bandwidth" - 20 min
  - URL: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/
  - Key insight: Memory bandwidth is single best GPU performance indicator
  - Example: A100 vs V100 speedup = 1.73√ó ‚âà bandwidth ratio (1555/900)
- [X] Skim: Roofline model (Wikipedia) - 15 min
  - Formula: Performance = min(Peak Compute, Bandwidth √ó Arithmetic Intensity)
  - LLMs hit slanted roof (memory-bound, not compute-bound)
- [X] Review: FSDP concepts - 10 min
  - Recognized: FSDP = ZeRO Stage 3 (PyTorch implementation)
  - Skipped PyTorch syntax (not needed for concept understanding)

**Practice Completed**:
- [X] Sketched: Communication patterns for DP, FSDP, TP, PP - 25 min
  - All-reduce (DP), all-gather + reduce-scatter (FSDP)
  - All-reduce within TP group (TP), point-to-point (PP)
- [X] Analyzed: Big O scaling for each parallelism strategy - 45 min
  - DP: O(P), FSDP: O(P), TP: O(B√óS√óH√óL), PP: O(B√óS√óH√óN)
  - Compared communication volume, frequency, bandwidth requirements
  - Synthesized trade-offs for interview answers

**Knowledge Check** (15 min):
- [X] 70% Day 3 content + 30% Review
- [X] Score: **99.0% (9.9/10)** - A+
  - Q1-Q7 (Day 3): 99.3% - Excellent understanding of hardware bottlenecks
  - Q8-Q10 (Review): 98.3% - Perfect retention of ZeRO and TP concepts
  - **User correction**: Caught bubble time approximation, should be (N-1)/(M+N-1) not (N-1)/M ‚úÖ
  - **User correction**: Noted TP > FSDP ranking for GPT-3 (not FSDP > TP) ‚úÖ

**Quick Reference Created**:
- [X] Day10-Quick-Reference.md - Comprehensive 11-section cheat sheet
  - GPU performance fundamentals, Roofline model
  - Communication patterns (4 strategies)
  - Complexity comparison table with GPT-3 examples
  - Scaling trade-offs (pros/cons/when to use)
  - Interview Q&A (ready-to-use answers)
  - Communication volume calculation details ‚≠ê NEW

**Day 3 Final Status**: ‚úÖ **EXCEEDED TARGETS**
- ‚è±Ô∏è Total time: ~2.25 hours (slightly over 2-hour target, but high efficiency)
- üìä Final readiness: **90%+** for hardware/communication interview questions
- üéØ Topics mastered: 6/6 at interview-ready level
- üí° Key insights:
  - Memory bandwidth > TFLOPS for LLM performance
  - TP limited to 8 GPUs per node (hardware constraint)
  - PP has lowest communication volume but bubble time overhead
  - FSDP trades 1.5√ó communication for N√ó memory savings

**Target**: Understand parallelism trade-offs and hardware bottlenecks at interview level ‚úÖ **ACHIEVED**

---

**Day 4: Inference Optimization (2 hours)** ‚úÖ **COMPLETED (2025-11-07)**

**Topics** (6 topics):
15. **KV-cache** - how it works, O(n¬≤)‚ÜíO(n) (Gap Q187)
16. **Quantization** - INT8, INT4 basics (Gap Q187)
17. **Continuous batching** (Gap Q187)
18. **Speculative decoding** (Gap Q187)
19. Multi-query attention (MQA)
20. Serving frameworks - vLLM overview

**Study**:
- [X] Read: vLLM paper (abstract + key sections) - 40 min
  - URL: https://arxiv.org/abs/2309.06180
  - Key concepts: PagedAttention, continuous batching (iteration-level scheduling)
- [X] Read: "KV-cache explained" blog - 15 min
  - URL: https://huggingface.co/blog (derived memory formula: 2√óH√óL√óB)
- [X] Read: Speculative decoding - 15 min
  - URL: https://huggingface.co/blog/whisper-speculative-decoding
  - Key insight: Draft model + parallel verification, synchronous vs continuous batching
- [X] Read: MQA & GQA - 15 min
  - URL: https://medium.com/@maxshapp/grouped-query-attention-gqa-explained-with-code-e56ee2a1df5a
  - Key concepts: Shared K/V heads (MHA: 32, MQA: 1, GQA: 4 groups)
- [X] Read: Quantization Overview - 15 min
  - URL: https://medium.com/@kimdoil1211/speeding-up-large-language-models-a-deep-dive-into-gptq-and-awq-quantization-0bb001eaabd4
  - Key concepts: GPTQ (Hessian-based), AWQ (activation-aware)

**Practice**:
- [X] Create: Inference optimization cheat sheet - 20 min
  - 6 topics: KV-cache, Quantization, Continuous batching, Speculative decoding, MQA/GQA, PagedAttention
  - Format: What it is + What problem it solves + Key trade-off

**Knowledge Check** (10 min):
- [X] 70% Day 4 content + 30% Review
- [X] Score: **97.5% (9.75/10)** - A+
  - Q1-Q7 (Day 4): 97.9% - Strong understanding of all 6 techniques
  - Q8-Q10 (Review): 96.7% - Excellent retention of ZeRO, TP, Roofline model
  - **Critical correction**: Speculative decoding batch size reasoning (75%) - ragged tensor problem, not continuous batching issue (user caught error, cited arxiv.org/html/2510.22876v1)

**Quick Reference Created**:
- [X] Day11-Quick-Reference.md - Comprehensive inference optimization cheat sheet
  - KV-cache memory formula: 2√óH√óL√ó2 bytes (FP16)
  - All 6 techniques with trade-offs
  - Interview-ready format

**Day 4 Final Status**: ‚úÖ **COMPLETED**
- ‚è±Ô∏è Total time: ~2h 10min (10 min over target, but covered all 6 topics)
- üìä Final readiness: **90%+** for inference optimization interview questions
- üéØ Topics mastered: 6/6 at interview-ready level
- üí° Key insights:
  - KV-cache: O(n¬≤)‚ÜíO(n), but memory cost = 2√óH√óL√ó2√óS bytes
  - Continuous batching = iteration-level scheduling (from Orca)
  - Speculative decoding: Ragged tensor problem when sequences accept different numbers of tokens (solutions: Masking/Rollback/Dynamic Padding)
  - Small batch benefits: GPU utilization + lower acceptance variance + less ragged tensor overhead
  - PagedAttention: Block-level memory management, eliminates fragmentation
  - MQA/GQA: Memory savings via shared K/V heads
  - Quantization: GPTQ (Hessian) vs AWQ (activation-aware)

**Target**: Can explain all 4 Q187 methods confidently, understand vLLM architecture ‚úÖ **ACHIEVED**

---

**Day 5: Calculations & Transformer Parameters (2 hours)** ‚úÖ **COMPLETED (2025-11-08)**

**Topics** (4 topics):
21. FLOPs calculation - forward/backward pass
22. Memory calculation - weights, optimizer, activations
23. **QKV projections** - parameter calculation (Gap Q189)
24. Transformer parameter counting

**Study**:
- [X] Read: "Transformer Math 101" (EleutherAI) - 40 min
  - URL: https://blog.eleuther.ai/transformer-math/
  - Key concepts: Parameter counting formulas, Chinchilla scaling law, activation memory

**Practice**:
- [X] Calculate: Parameters for GPT-2 (124M), GPT-3 (175B)
  - Formula: V√óH + (4H¬≤ + 2H√ó4H)√óL
  - GPT-2: 123.5M params ‚úì
  - GPT-3: 175B params ‚úì
- [X] Calculate: Memory for training 7B model on A100 (80GB)
  - Model states (no parallelism): 112 GB (need parallelism!)
  - With ZeRO-3 (N=4): 28 GB per GPU
  - Activation memory (full checkpointing): 2√ós√ób√óh√óL
  - Max batch size: 59 samples/GPU, 236 global ‚úì

**Knowledge Check** (10 min):
- [X] Score: **99.6% (9.96/10)** - A+
  - Q1-Q7 (Day 5): 100% - Perfect calculations (parameters, memory, batch size)
  - Q8-Q10 (Review): 97.7% - Excellent retention (memory bandwidth, KV-cache, ZeRO)

**Progress Validation** (15 min):
- [X] Quick 24-topic check: **83% Know** (25/30 high-priority topics)
  - Area 1 (Distributed Training): 75% ‚úÖ
  - Area 2 (Memory Optimization): 83% ‚úÖ
  - Area 3 (Hardware): 67% üü°
  - Area 4 (Parallelism): 100% ‚úÖ‚úÖ
  - Area 5 (Inference): 100% ‚úÖ‚úÖ

**Day 5 Final Status**: ‚úÖ **COMPLETED**
- ‚è±Ô∏è Total time: ~2h 15min (study + practice + validation)
- üìä Final readiness: **99%+ for calculations & transformer parameters**
- üéØ Topics mastered: 4/4 at interview-ready level
- üí° Key insights:
  - Attention params: 4H¬≤ (not 4H¬≤√ón_heads - heads split H!)
  - Chinchilla law (D=20P): Optimizes training cost, not total cost
  - Activation memory: 2sbhL with full checkpointing
  - Memory states require parallelism for 7B+ models (112 GB > 80 GB)
  - ZeRO-3 enables training by sharding model/optimizer/gradients

**Week 2 Day 1-5 Status**: ‚úÖ **LLM SYSTEMS GAP CLOSURE SUCCESSFUL**
- **Target**: 60-70% interview ready ‚Üí **Achieved**: 83% ‚úÖ
- All Gap Q182-189 topics covered with strong understanding
- Knowledge check average: 92% across 5 days (85%, 98%, 99%, 97.5%, 99.6%)
- Ready to move to Day 6-7: Statistical Testing

**Target**: Can calculate transformer params and memory requirements in interview setting ‚úÖ **ACHIEVED**

---

**Day 6-7: Statistics & Probability (Days 13-14) (4-5 hours)** ‚ö†Ô∏è **EXTENDED, CONTINUES TO WEEK 3 DAY 1**

**Rationale**: Comprehensive 43-topic assessment revealed 18.6% baseline (vs estimated 65%) with 8 Dunno + 25 Unsure topics. Extended to 3 days (Week 2 Day 6-7 + Week 3 Day 1) for realistic coverage.

**Assessment Completed** (Day 13 start):
- [X] Comprehensive topic coverage check (see `gap_analysis/Week2-Statistics-Topic-Check.md`)
- [X] Results: 8 Know, 25 Unsure, 8 Dunno ‚Üí 18.6% baseline readiness
- [X] Decision: Extend from Day 6-7 (2-3 hours) to Day 6-8 (6-7.5 hours total)

---

**Day 6 (Day 13): Regression Diagnostics + Covariance (2-2.5 hours)** ‚úÖ **COMPLETED (2025-11-09)**

**Study** (80-100 min):
- [X] **Section 4: Regression Diagnostics** (60 min) - 4 Dunno topics
  - Durbin-Watson test (autocorrelation in residuals)
  - Breusch-Pagan test (heteroscedasticity detection)
  - Shapiro-Wilk test (normality of residuals)
  - VIF (Variance Inflation Factor for multicollinearity)
  - Used Gemini deep research for comprehensive summary (no hands-on practice)
- [X] **Covariance vs Correlation** (20 min) - Gap Q3 (0%)
  - Watched both StatQuest videos at 2√ó speed (~20 min total)
  - Units, bounds [-1,1], interpretation, when to use each

**Knowledge Check** (15 min):
- [X] Score: **99.5% (995/1000)** - A+
  - Q1-Q7 (Day 6): 99.3% - Excellent diagnostics & covariance understanding
  - Q8-Q10 (Review): 100% - Perfect retention
  - Caught error in Q6 (impossible correlation value)

**Quick Reference** (20-30 min):
- [X] Created `references/Day13-Quick-Reference.md`: Regression Diagnostics & Covariance (comprehensive, 13 sections)

**Update Documents** (10 min):
- [X] Update `ML-Interview-Prep-Plan.md` (mark Day 6 complete)
- [X] Update `00-CONVERSATION-SUMMARY.md` (Day 13 section)
- [X] Update `Daily-Knowledge-Check-Protocol.md` (Day 13 entry)
- [X] Update `gap_analysis/Week2-Statistics-Topic-Check.md` (progress)

**Target**: Move 5 topics from Dunno/Unsure ‚Üí Know (Section 4 + covariance) ‚úÖ **ACHIEVED**

---

**Day 7 (Day 14): MLE + Hypothesis Testing (2-2.5 hours)** ‚úÖ **COMPLETED (2025-11-10)**

**Study** (80-100 min):
- [X] **MLE Derivations** (40 min) - Gap Q29 (0%)
  - Exponential distribution: ŒªÃÇ = 1/mean ‚úÖ
  - Gaussian distribution: ŒºÃÇ, œÉÃÇ¬≤ ‚úÖ
  - Watched StatQuest videos + practice derivations
- [X] **Chi-square test** (20 min) - Section 3.8
  - Goodness of fit, independence testing ‚úÖ
- [X] **Hypothesis Testing Core** (30 min) - Critical Unsure
  - T-test vs Z-test (n<30 vs n‚â•30, assumptions) ‚úÖ
  - Normal distribution calculations (P(X>2), Z-scores) ‚úÖ

**Knowledge Check** (15 min):
- [X] 10 questions: 7 Day 7 content, 3 review (Day 6)
  - Score: **86.5% (B+/A-)**
  - New content: 88.6% (7 questions)
  - Review content: 81.7% (3 questions)

**Quick Reference** (20-30 min):
- [X] Created `references/Day14-Quick-Reference.md`: MLE & Hypothesis Testing

**Update Documents** (10 min):
- [X] Updated all files + SM-2 schedule

**Day 14 Results Summary** (2025-11-10):
- ‚è±Ô∏è **Total time**: ~2 hours (study + knowledge check + docs)
- üí° **Key learnings**:
  - MLE exponential: ŒªÃÇ = 1/mean (log-likelihood trick)
  - MLE Gaussian: ŒºÃÇ = xÃÑ, œÉÃÇ¬≤ = Œ£(x·µ¢-ŒºÃÇ)¬≤/n (n, not n-1!)
  - T-test: wider tails than z-test (accounts for œÉ estimation uncertainty)
  - Chi-square: Œ£(O-E)¬≤/E, df=(r-1)(c-1) for contingency table
- üìù **Created**: Day14-Quick-Reference.md (comprehensive 15-section guide)
- üìä **Knowledge Check: 86.5% (B+/A-)** - Strong understanding, minor gaps in assumptions
- üîÑ **SM-2 updates**: 3 review items updated, 3 new topics added (now tracking 40 items)

**Success Criteria**: ‚úÖ All met
- ‚úÖ Can derive MLE for exponential and Gaussian distributions
- ‚úÖ Can explain when to use t-test vs z-test with assumptions
- ‚úÖ Understand chi-square test for goodness of fit and independence
- ‚úÖ Can calculate normal distribution probabilities using Z-scores

**Target**: Move 3 topics from Dunno/Unsure ‚Üí Know (MLE, chi-square, t-test) ‚úÖ **ACHIEVED**

---

**Week 2 Expected Outcomes**:
- ‚úÖ **LLM Systems**: 83% interview ready (25/30 high-priority topics covered) - **EXCEEDED TARGET**
  - Can explain: Data/model/tensor parallelism, ZeRO, FSDP, KV-cache, quantization, batching
  - Can calculate: Transformer parameters, FLOPs, memory requirements
  - Can discuss: 3 key papers (Megatron-LM, ZeRO, vLLM)
  - Knowledge check average: 92% across 5 days
- ‚è≥ **Statistics & Probability**: In progress (18.6% ‚Üí target 65-70%)
  - Day 6-7 complete (regression diagnostics, covariance, MLE, hypothesis testing)
  - Continues to Week 3 Day 1 for completion
- ‚è∏Ô∏è **Advanced RAG**: Deferred to Week 3 or later
- ‚è∏Ô∏è **ML Evaluation**: Deferred to Week 3 or later

---

### Week 3: Statistics Completion + System Design ‚ö†Ô∏è **ADJUSTED FROM WEEK 2 OVERFLOW**

**Goal**: Complete statistics gap closure (Day 1), then strengthen system design from 70% ‚Üí 85%

**Context**: Week 2 statistics work extended into Week 3 Day 1. PyTorch and other topics shifted accordingly.

---

**Day 1 (Day 15): Statistics Completion - A/B Testing + Fundamentals (2-2.5 hours)** ‚úÖ **COMPLETED (2025-11-11)**

**Rationale**: Completing 3-day statistics deep dive from Week 2 (Day 6-8 plan)

**Study** (80-100 min):
- [X] **Regularization as Bayesian Prior** (20 min) - Section 6.7
  - L2 ‚âà Gaussian prior (N(0, œÑ¬≤)), L1 ‚âà Laplace prior ‚úÖ
  - MAP = maximize (log likelihood + log prior) ‚úÖ
  - Read: https://bjlkeng.io/posts/probabilistic-interpretation-of-regularization/
- [X] **A/B Testing Design & Pitfalls** (30 min) - Section 3.9 (MUST-KNOW)
  - Metric choice (north star vs tactical), segmentation ‚úÖ
  - Pitfalls: novelty effect, multiple comparisons, selection bias, Simpson's paradox ‚úÖ
  - Used Gemini-generated report (original resources too long)
- [X] **Fundamentals Refresh** (30 min) - Section 1 (all Unsure)
  - PDF/CDF/PMF definitions ‚úÖ
  - Distributions: Binomial (np(1-p) variance), Geometric (1/p mean), Poisson (Œª), Exponential ‚úÖ
  - CLT vs LLN: applications and concrete examples ‚úÖ
  - Watched video series for each distribution

**Knowledge Check** (15 min):
- [X] 10 questions: 7 Day 1 content, 3 review (overdue items)
  - Score: **92.0% (A-)**
  - New content: 88.6% (7 questions)
  - Review content: 100% (3 questions)

**Quick Reference** (20-30 min):
- [X] Created `references/Day15-Quick-Reference.md`: A/B Testing & Statistics Fundamentals

**Update Documents** (10 min):
- [X] Update `ML-Interview-Prep-Plan.md` (mark Week 3 Day 1 complete)
- [X] Update `00-CONVERSATION-SUMMARY.md` (Day 15 section)
- [X] Update `Daily-Knowledge-Check-Protocol.md` (Day 15 entry)
- [ ] Update `gap_analysis/Week2-Statistics-Topic-Check.md` (deferred - need full reassessment)

**Day 15 Results Summary** (2025-11-11):
- ‚è±Ô∏è **Total time**: ~2.5 hours (study + knowledge check + docs)
- üí° **Key learnings**:
  - Regularization as prior: L2 = Gaussian N(0, œÑ¬≤), L1 = Laplace, Œª ~ 1/œÑ¬≤
  - A/B testing: One primary metric, watch Simpson's paradox, avoid peeking
  - Binomial variance: np(1-p) derived from sum of independent Bernoulli trials
  - CLT enables inference: CI, hypothesis tests work even with non-normal data
- üìù **Created**: Day15-Quick-Reference.md (comprehensive 9-section guide)
- üìä **Knowledge Check: 92.0% (A-)** - Strong understanding, minor gaps in CLT examples
- üîÑ **SM-2 updates**: 3 review items (all 100%), 4 new topics added (now tracking 44 items)
- üéØ **Review retention**: Perfect scores on all overdue items (Megatron 77%‚Üí100%, Precision-Recall 88-92%‚Üí100%)

**Target Achieved**: Statistics gap closure progressing - core fundamentals solid (88-100% on new topics)

---

**Day 2 (Day 16): PyTorch Basics (2-3 hours)** ‚úÖ **COMPLETED (2025-11-12)** ‚≠ê **SHIFTED FROM WEEK 3 DAY 1**

**Rationale**: Basic PyTorch literacy needed for research-heavy ML roles. Goal is reading comprehension, not production coding.

**Study** (1 hour):
- [X] PyTorch Quickstart Tutorial (30 min) ‚úÖ
  - URL: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html
  - Focus: Tensors, Dataset/DataLoader, nn.Module structure
- [X] Autograd Mechanics (30 min) ‚úÖ
  - URL: https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html
  - Understand: .backward(), .grad, computational graph

**Practice** (1.5 hours):
- [X] Implement logistic regression in PyTorch (60 min) ‚úÖ
  - Defined nn.Module class with nn.Sequential
  - Forward pass, BCELoss, Adam optimizer
  - Achieved 69.0% test accuracy (vs sklearn 67.5%) ‚úÖ
  - Implementation: `notebooks/day16-pytorch.ipynb`
- [X] Read PyTorch FSDP code (30 min) ‚úÖ
  - Read `_pre_forward_unshard` function
  - Recognized: all-gather (unshard), reduce-scatter (reshard), prefetching
  - Connected to Week 2 distributed training concepts ‚úÖ

**Knowledge Check** (15 min):
- [X] 10 questions: 7 PyTorch content, 3 review (overdue items)
  - Score: **92.5% (A-)**
  - PyTorch content: 87.9% (7 questions)
  - Review content: 98.3% (3 questions - KNN, Boosting, MLE)

**Day 16 Results Summary** (2025-11-12):
- ‚è±Ô∏è **Total time**: ~2.5 hours (study + implementation + FSDP reading + knowledge check)
- üí° **Key learnings**:
  - PyTorch training loop: backward() ‚Üí step() ‚Üí zero_grad() (both orders work!)
  - torch.no_grad() for evaluation (stops gradient calc, saves memory)
  - BCELoss (needs [0,1]) vs BCEWithLogitsLoss (takes logits)
  - FSDP patterns: all-gather before forward, reduce-scatter after (ZeRO Stage 3)
  - CUDA streams: parallel task queues enable overlap of communication + computation
- üìù **Created**: `notebooks/day16-pytorch.ipynb` (logistic regression implementation)
- üìä **Knowledge Check: 92.5% (A-)** - Strong fundamentals, FSDP concepts directional
- üîÑ **SM-2 updates**: 3 review items (all 95-100%), 5 new PyTorch topics added (reorganized from 7 for efficient review)
- üéØ **Review retention**: 98.3% on overdue items (KNN 7d overdue, Boosting 5d overdue, MLE 1d overdue)
- üóÇÔ∏è **Cleanup**: Removed duplicate topic `llm_tensor_parallel_comm` (merged into `llm_megatron`)
- üìã **Topic organization**: Merged tightly-coupled concepts (training mechanics, FSDP internals) for more efficient review

**Target Achieved**: Basic PyTorch literacy - can read code in interviews, understand distributed patterns ‚úÖ

---

**Day 3-5 (Day 17-19): ML Technology Deep Dives (6 hours over 3 days, 2h/day)** üîÑ **IN PROGRESS**

**Pre-study**: Topic Coverage Check ‚úÖ **COMPLETED (2025-11-13)**
- ‚úÖ Created comprehensive 64-item checklist (9 categories)
- ‚úÖ Self-assessed: 0% Know, 37.5% Unsure, 62.5% Dunno
- ‚úÖ Identified top 5 priorities: Kafka, Feature Stores, Airflow, Docker, K8s

**Day 3 (Day 17, Thursday 2025-11-13) - 2 hours:** ‚úÖ **COMPLETED**
- [x] Kafka fundamentals (1 hour)
  - Topics, partitions, consumer groups, offset management
  - Replication & durability (ISR, acks configuration)
  - Use cases: Event streaming, real-time pipelines
- [x] Feature Stores basics (30 min)
  - Online vs offline architecture
  - Point-in-time correctness
  - When to use vs database
- [x] Knowledge check (30 min): 95.1% (A) - 7 new, 3 review

**Day 4 (Day 18, Friday 2025-11-14) - 2 hours:** ‚úÖ **COMPLETED**
- [x] Airflow fundamentals (1 hour)
  - DAGs, operators, tasks, scheduling
  - Idempotency & backfills (critical for interviews)
  - Executors: Local, Celery, Kubernetes
- [x] Feature Stores deep dive (30 min)
  - Feature transformation patterns (streaming vs batch)
  - Feast architecture & materialization
- [x] Knowledge check (15 min): 95.5% (A+) - 7 new, 3 review

**Completion Summary**:
- Study time: ~2 hours (Airflow + Feature Store transformations)
- Knowledge check score: 95.5% (A+)
  - Airflow: 97.5% - Executors 100%, catchup 100%, idempotency 95%, DAGs 95%
  - Feature Store transformations: 98.3% - Perfect batch vs streaming decision framework
  - Review retention: 90% - Kafka 100%, Feature Store 100%, backward pass 70% (gap identified)
- Quick reference created: references/day18-airflow-featureStoreTransform.md

**Day 5 (Day 19, Saturday 2025-11-15) - 2 hours:** ‚úÖ **COMPLETED**
- [x] Docker basics (30 min)
  - Dockerfile, images, containers, registries
  - Best practices: Multi-stage builds, GPU support
- [x] Kubernetes basics (1 hour)
  - Pods, deployments, services, ingress
  - Resource management (CPU/GPU limits)
  - Autoscaling (HPA, VPA)
- [x] Knowledge check (15 min): 89.5% (B+/A-) - 7 new, 3 review

**Target**: Bring ML infra from 0-37.5% ‚Üí 60-70% interview readiness ‚úÖ **ACHIEVED: 65%**

---

**Day 6 (Day 20, Saturday 2025-11-16) - 2 hours:** ‚úÖ **COMPLETED**

**Mock Interview**: YouTube Recommendation System (60 min)
- [x] Problem 1: Design YouTube recommendation system
  - Focus: Candidate generation, ranking, serving architecture
  - Score: 78/100 (B+) - Strong for first practice
  - Solution: 3-stage cascade (100M ‚Üí 1K ‚Üí 100 ‚Üí 20)
  - Data pipeline: Kafka‚ÜíFlink‚ÜíRedis + Spark batch
  - Training: watch_time / duration, 5% randomized traffic, IPS
  - A/B testing: Per-user, 1-2 weeks

**Extended Discussions** (60 min):
- [x] Latency vs QPS relationship (batching increases throughput)
- [x] Two-tower pre-computation (user vs item embeddings)
- [x] A/B test sample size calculation
- [x] Training data bias solutions

**Knowledge Check** (15 min): 91% (A-/A) - REVISED from 89.5%
- Review: 95% (VIF, Airflow idempotency, continuous batching)
- New: 87.1% (system design concepts)
- Critical gap: Throughput calculations - REVISED to 85% after clarification
- **User insight**: "1K predictions = 1 REQUEST, not 1K requests!" ‚úÖ

**Follow-up Session (2025-11-17, 30 min)**: ‚≠ê **TYPICAL NUMBERS CHEATSHEET ADDED**
- [x] Identified real gap: Not formula knowledge, but realistic numbers to plug in
- [x] Created comprehensive cheatsheet with typical values:
  - Server configs (cores, memory, GPU types, costs)
  - Batch sizes (ANN=1, XGBoost=1K candidates, DNN=32-256)
  - Latencies (Redis=0.1-1ms, XGBoost=5-10ms, ANN=10-20ms, DNN=50ms)
  - Parallelism factors (CPU-bound=10-16√ó, memory-bound=4-8√ó)
  - Decision tree for "I don't know the numbers"
  - Quick estimation examples (XGBoost, DNN, ANN)
  - Common pitfalls & interview-ready template
- [x] Added 227-line section to `references/day20-system-design-youtube-rec.md`
- **Key meta-learning**: User demonstrated strong self-awareness of learning gaps

**Completion Summary**:
- Mock interview score: 78/100 (B+)
  - Strengths: Requirements (9/10), architecture (8/10), communication (8/10)
  - Needs work: Scaling calculations (6.5/10) ‚ùå ‚Üí **GAP CLOSED with cheatsheet** ‚úÖ
- Knowledge check: 91% (A-/A) - revised after throughput correction
  - Perfect: Data pipelines (100%), bias handling (100%), A/B testing (100%)
  - Improved: Throughput calc (70% ‚Üí 85% after 1K predictions clarification)
  - Weak: GPU scaling (50%) - can improve with practice
- Key learning: **Throughput = 1 REQUEST (scoring N candidates) / Latency**, not N/Latency!
- **Critical addition**: Typical Numbers Cheatsheet now available for future system design interviews

**Day 7 (Day 21, Sunday 2025-11-17) - 2 hours:** ‚úÖ **COMPLETED**

**Practice Problems** (2-3 problems √ó 45-60 min each):
- [x] Problem 2: Design fraud detection system
  - Focus: Real-time inference, feature engineering, model monitoring, XGBoost vs DNN
  - **Score**: 85/100 (A-) - Strong design across all areas
  - **Architecture**: Kafka‚ÜíFlink‚ÜíRedis + Snowflake, XGBoost with dynamic batching ($6K/year)
- [ ] Problem 3: Design search ranking system (skipped - optional)
- [ ] Problem 4 (optional): Design ad click prediction system (skipped)

**Focus Areas for Day 21**: ‚úÖ **ALL ACHIEVED**
- [x] **CRITICAL**: Scaling calculations (QPS ‚Üí servers ‚Üí cost) for every component - Calculated LogReg, XGBoost, DNN with/without batching
- [x] **CRITICAL**: Throughput formula (Batch Size / Latency) - Applied correctly, understood dynamic batching
- [x] Specific tool names (Kafka, Flink, Redis, FAISS) - All used correctly
- [x] Cost estimation ($/year for all components) - $600, $6K, $90K compared

**Knowledge Check**: **97.0% (A+)**
- Day 21 content: 99.3% (7 questions on fraud detection)
- Review content: 91.7% (residual plots, roofline, throughput calc)

**Completion Summary**:
- Mock interview score: 85/100 (A-) - **+7 points from Day 20!**
  - Feature engineering: 9.5/10 (20 comprehensive features)
  - Cost analysis: 9/10 (LogReg $600, XGBoost $6K, DNN $90K)
  - Architecture: 8.5/10 (Kafka‚ÜíFlink‚ÜíRedis, cold start handling, sliding windows)
  - Dynamic batching: 9/10 (50√ó throughput improvement)
- Knowledge check: 97% - **+6 points from Day 20 (91%)!**
  - Perfect scores on model selection, features, Flink vs Snowflake, sliding windows, cold start, manual review
- Key improvements:
  - Feature engineering: 7/10 ‚Üí 9.5/10
  - Cost analysis: 6/10 ‚Üí 9/10
  - Throughput calculations: Now calculates with/without batching
- Quick reference created: `references/day21-fraud-detection-system.md`

**Memorize** ‚úÖ:
- [x] Common architectures: Two-tower, cascade, lambda architecture
- [x] Scale numbers: QPS targets (1K, 10K, 100K+), latency (<10ms, 10-100ms, 100-500ms)
- [x] **NEW**: Dynamic batching is COST OPTIMIZATION (12-50√ó savings), not just scaling!

---

**Week 3 Note**: Schedule adjusted to accommodate ML Tech deep dive (3 days instead of 2). Advanced RAG moved to Week 4 Day 1-2 to enable comprehensive gap reassessment after all study complete.

---

### Week 4: Progress Check & Adaptive Planning ‚ö†Ô∏è **SUBJECT TO ADJUSTMENT**

**Goal**: Close Advanced RAG gap, then assess overall progress and decide next steps

**Context**: Week 4 serves as final gap closure + checkpoint. Advanced RAG must be studied BEFORE gap reassessment to enable meaningful evaluation of Q177-179.

---

**Day 1-2: Advanced RAG Architectures (2-3 hours)** ‚≠ê **MOVED FROM WEEK 3 DAY 6-7**

**Pre-study**: Topic Coverage Check (20 min) - if needed
- [x] ‚úÖ **COMPLETED Day 22**: List RAG subtopics: Retrieval methods (sparse, dense, hybrid), Reranking, FiD, ColBERT, DPR, etc.
- [x] ‚úÖ **COMPLETED Day 22**: Self-assess: know/unsure/dunno for each
  - **Result**: 86 topics assessed, 21.3% weighted baseline ‚Üí Day 1 studied 11 topics (7 new + 4 consolidated)

**Study**:

**Day 1 Topics** (7 new + 4 consolidated) - ‚úÖ **COMPLETED Day 22**:
- [x] ‚úÖ RRF (Reciprocal Rank Fusion) - Formula: Score = Œ£ 1/(k + rank_r(d)), k=60
- [x] ‚úÖ SPLADE (Learned Sparse) - FLOPS regularization, vocabulary expansion
- [x] ‚úÖ DPR (Dense Passage Retrieval) - TWO types of negatives (in-batch + hard from BM25)
- [x] ‚úÖ Cross-encoder reranking - Two-stage: bi-encoder retrieve ‚Üí cross-encoder rerank
- [x] ‚úÖ ColBERT (Late Interaction) - Token-level embeddings, MaxSim, 100√ó storage cost
- [x] ‚úÖ MMR (Maximal Marginal Relevance) - Diversity reranking with MINUS sign
- [x] ‚úÖ Lost-in-the-middle problem - LLMs ignore middle docs, mitigation strategies
- [x] ‚úÖ Consolidated 4 "unsure" topics: Dense/Sparse/Hybrid retrieval, Contrastive learning

**Day 1 Achievement (Day 22)**: 96% knowledge check (98.9% on new content)
- ‚úÖ Studied 11 topics: RRF, SPLADE, DPR, Cross-encoder, ColBERT, MMR, Lost-in-the-middle + 4 consolidations
- ‚úÖ Created `references/Day22-Advanced-RAG-Day1.md` quick reference (8 pages)
- ‚úÖ All 6 topics added to SM-2 schedule (fixed: ColBERT separate from reranking)
- üìä Estimated progress: 21.3% ‚Üí 40-45% weighted overall after Day 1

**Day 2 Topics** (7 new patterns + 3 consolidations) - ‚úÖ **COMPLETED Day 23**:
- [x] ‚úÖ **FiD (Fusion-in-Decoder)** - Gap Q177 closed (0%‚Üí100%), encode independently/decode jointly, FiD vs Long Context with prefix caching
- [x] ‚úÖ **GraphRAG** - Two modes: Local (entity) + Global (themes via community summaries)
- [x] ‚úÖ **RAFT** - P=0.8 golden+distractors, (1-P)=0.2 distractors-only, teach model to ignore distractors
- [x] ‚úÖ **Agentic RAG** - ReAct loop (Thought‚ÜíAction‚ÜíObservation), 3-5√ó cost, multi-tool
- [x] ‚úÖ **Multi-hop retrieval** - Three implementations (query decomp, agentic, GraphRAG) with trade-offs
- [x] ‚úÖ **Parent document retrieval** - Two storage systems (vector+parent), deduplication critical
- [x] ‚úÖ **Complex PDF parsing** - Parse vs multi-modal vs hybrid, table problem
- [x] ‚úÖ Review 3 "unsure": Multi-modal RAG, Query decomposition, Standard RAG pipeline

**Day 2 Achievement (Day 23)**: 96.3% knowledge check (A+)
- ‚úÖ Studied 7 new topics: FiD, GraphRAG, RAFT, Agentic RAG, Multi-hop, Parent doc, PDF parsing
- ‚úÖ Consolidated 3 "unsure" topics: Multi-modal RAG, Standard RAG pipeline, Query decomposition
- ‚úÖ Knowledge check: 98.6% on new content (exceptional mastery)
- ‚úÖ Created `references/Day23-Advanced-RAG-Day2.md` quick reference (comprehensive)
- ‚≠ê **Gap Q177 (FiD) closed: 0% ‚Üí 100%**
- üìä Estimated progress: 40-45% ‚Üí **52-55% weighted overall**, **68-72% high-priority** after Day 2

**Day 3 Topics (Optional)** - Evaluation + Final Consolidation:
- [ ] **Retrieval metrics** - Recall@K, Precision@K, MRR, NDCG (formulas + hand calculation)
- [ ] **End-to-end RAG metrics** - Faithfulness, Answer Relevance, Context Quality (RAGAs)
- [ ] **Context window optimization** - Truncation, compression, summarization strategies
- [ ] Review remaining "unsure": FAISS, HyDE, Query rewriting/expansion, Chunking strategies

**Practice** (Optional):
- [ ] Implement: Simple hybrid retrieval (BM25 + Sentence-Transformers + RRF)
- [ ] Calculate: Retrieval metrics by hand for sample scenario

**Progress Targets**:
- **Baseline**: 21.3% weighted (23.2% high-priority)
- **After Day 1**: ~40-45% weighted ‚úÖ
- **After Day 2**: **52-55% weighted**, **68-72% high-priority** ‚úÖ **ACHIEVED**
- **After Day 3 (optional)**: Target 55-60% weighted overall, **82% high-priority**
- **Success Criteria**: ‚â•82% high-priority (23/28 topics), ‚â•55% weighted overall
- **Current Status**: 68-72% high-priority is functional for interviews, Day 3 optional for polish

---

**Day 3-4 (Day 24-25): Gap Re-assessment (2-3 hours)** ‚úÖ **COMPLETED (2025-11-20 to 2025-11-21)**

**Activity**:
- [x] Re-test on ALL weak areas (45 questions over 2 days)
  - LLM systems (Q182-189): **89.4%** ‚úÖ (exceeded 85% target)
  - Statistical testing (Q181-182): **81.7%** ‚úÖ (strong understanding)
  - **Advanced RAG (Q177-179)**: **99.2%** ‚úÖ‚úÖ (exceptional! exceeded 75% target)
  - System design (Q145-165): **86.0%** ‚úÖ (exceeded 85% target)
  - ML infra (Q145-160 subset): **90.0%** ‚úÖ (far exceeded 75% target)
  - Unstudied weak areas: **68.8%** üü° (better than expected 30-50%)
- [x] Calculate improvement: **81.7% overall** (up from ~50% Day 6 baseline, **+31.7%**)
- [x] Identified remaining gaps: Bonus discovery areas (dropout, few-shot learning)

**Extended Session - Communication Patterns Clarification** (60+ min):
- [x] Clarified QPS calculation: Use GPU processing time only, not batch waiting time
- [x] Clarified batch collection time: Use per-GPU QPS, not total QPS
- [x] Clarified communication volume formulas: Distinguish logical vs physical network traffic
  - DP/FSDP: 2P per step (ring all-reduce overhead)
  - TP: 8√óB√óS√óH per layer (4 all-reduces √ó 2√ó ring overhead)
  - PP: B√óS√óH per stage boundary (point-to-point, no ring overhead)
- [x] Created comprehensive reference: `references/Day25-Communication-DynamicBatching.md`

**Assessment Results Summary**:

| Category | Score | Status | Notes |
|----------|-------|--------|-------|
| **LLM Systems** | 89.4% | ‚úÖ | Strong scaling, ZeRO, KV-cache, communication patterns |
| **Statistics** | 81.7% | ‚úÖ | MLE, t-tests, regression diagnostics |
| **Advanced RAG** | 99.2% | ‚úÖ‚úÖ | **EXCEPTIONAL** - FiD, GraphRAG, RAFT, hybrid retrieval |
| **ML Infrastructure** | 90.0% | ‚úÖ | Kafka, Airflow, Feature Stores |
| **System Design** | 86.0% | ‚úÖ | YouTube + Instagram recommendations |
| **Unstudied Weak** | 68.8% | üü° | Transfer learning, spaced repetition working |
| **Overall** | **81.7%** | ‚úÖ | **Up from ~50% Day 6 baseline** |

**Decision**: ‚úÖ **Option A - Start Projects** (all critical gaps closed, targets exceeded!)

**Readiness Update**:
- Overall: 75% (Week 1) ‚Üí **85%** (Week 4) ‚úÖ
- LLM Systems: 30% ‚Üí **89.4%** (+59.4%) ‚≠ê
- Statistics: 65% ‚Üí **81.7%** (+16.7%)
- Advanced RAG: 21.3% ‚Üí **99.2%** (+77.9%) ‚≠ê‚≠ê
- ML Infrastructure: 0-37.5% ‚Üí **90.0%** (+52.5%+) ‚≠ê
- System Design: 0% ‚Üí **86%** (+86%) ‚≠ê

**Key Achievements**:
- ‚úÖ All studied areas ‚â•80% (target met)
- ‚úÖ Gap Q177 (FiD): 0% ‚Üí 100%
- ‚úÖ Communication patterns confusion resolved with Day25 reference
- ‚úÖ User caught 3 scoring errors (exceptional attention to detail)
- ‚úÖ Ready for senior-level ML Engineer interviews

---

**Day 5-7 (Day 26-28): Start Projects** ‚úÖ **OPTION A CHOSEN** (gap reassessment: 85% readiness)

**Day 5 (Sat, Nov 22 - 30 min)** ‚úÖ **COMPLETED**

**Knowledge Check (15-20 min)**:
- [X] 10 review questions from knowledge schedule (prioritize items due/overdue)
- Score: **80.0% (800/1000)** - B/B+
- Perfect scores (100%): 7 topics - Shapiro-Wilk, Distributions, CLT/LLN, Regularization, Speculative decoding, SPLADE, Communication patterns
- Good scores (75%): Chi-square, Durbin-Watson
- Weak item: FSDP stream sync (50%) - 3rd review, still struggling with CUDA streams

**Project Selection (15-30 min)**:
- [X] Choose: **Full Project 4 (Option B, ~12 hours over 2 weeks)** - Changed from Mini RAG
- [X] Decision rationale: 1 day insufficient for quality portfolio project, extended timeline realistic
- [X] Plan: Data source (ArXiv papers on RAG/LLMs), architecture (hybrid retrieval + RRF fusion + Ragas evaluation), tech stack (sentence-transformers, FAISS, rank-bm25, OpenAI API, Ragas)
- [X] Created subfolder: `projects/rag-qa-system/`
- [X] Created comprehensive `project-plan.md` (450+ lines)
  - Problem statement, architecture overview, tech stack decisions
  - Complete timeline (Weekend + Week 5, 12 hours total)
  - ArXiv papers list (20-30 URLs)
  - Full code structure (~800 lines)
  - Requirements list, evaluation plan, interview talking points

**Day 5 Summary**:
- ‚è±Ô∏è Total time: ~30 min (knowledge check + project planning)
- üìä Knowledge check: 80% (7 perfect scores, communication patterns improved 75%‚Üí100%)
- üìù Project plan: Comprehensive specification document created
- üéØ Progress: Ready for Day 6 light prep

---

**Day 6 (Sun, Nov 23 - 30 min)** ‚úÖ **COMPLETED**

**Knowledge Check (15-20 min)**:
- [X] 10 review questions from knowledge schedule (all overdue items)
- Score: **87.5% (875/1000)** - A-/B+
- Perfect scores (100%): 7 topics - PyTorch (no_grad, BCELoss), FSDP internals (breakthrough!), Airflow executors, GPU scaling, All concepts for regression metrics
- Good scores (75%): nn.Module (forgot super().__init__), Docker multi-stage, K8s Deployment, Regression metrics (missing R¬≤ formula)
- Failed: Adam optimizer (50%) - Formulas missing, reset to review tomorrow

**RAG Project Setup (30 min)**:
- [X] Downloaded **32 ArXiv papers** (73.1 MB) to `data/raw/` - Added 4 papers beyond list, including 1 from 2025!
  - Core RAG: 7 papers (Lewis, FiD, Lost in Middle, Self-RAG, RAPTOR, RAFT, GraphRAG)
  - Retrieval: 4 papers (ColBERT, DPR, SPLADE, Hybrid)
  - Evaluation: 3 papers (RAGAS, ARES, RGB)
  - Advanced: 11 papers (Query rewriting, HyDE, Step-back, Active RAG, Vision RAG, Deliberative RAG, etc.)
  - Surveys: 3 papers (Gao, Li, Asai)
  - Multi-hop: 2 papers (ReAct, Multi-hop QA)
  - 2025 papers: Embedding limits (Weller)
- [X] Created folder structure: data/raw, data/processed, data/eval, src/, evaluation/, tests/, outputs/eval_results, outputs/logs
- [X] Created `requirements.txt` with 28 dependencies (sentence-transformers, FAISS, BM25, OpenAI, Ragas, etc.)
- [X] Created `download_papers.py` script for automated ArXiv downloads
- [X] Created `papers_to_download.md` reference list with 30 papers

**Day 6 Summary**:
- ‚è±Ô∏è Total time: ~30 min (knowledge check + RAG project setup)
- üìä Knowledge check: 87.5% (FSDP breakthrough 50%‚Üí100%, Adam optimizer gap identified)
- üìö Papers: 32 ArXiv papers downloaded (600-800 pages corpus)
- üìÅ Project: Complete folder structure + requirements ready
- üéØ Progress: Ready for Week 5 Day 1 implementation

**Day 7 (Mon, Nov 24 - 2-3 hours)** ‚úÖ **COMPLETED** - Main implementation day

**Knowledge Check (15 min)**:
- [X] 10 review questions (due/overdue items)
- Score: **97.0% (A+)** - 8 perfect, 2 partial
- **Adam optimizer mastered**: 50%‚Üí100% (all 5 formulas perfect)
- Perfect scores: Memory calc, batch size, Chinchilla, activation mem, residual plots, PyTorch training, Kafka
- User caught 3 scoring errors (Q2, Q5, Q9 - all valid corrections)

**Core Implementation (2 hours)**:
- [X] Data loading & chunking with PyMuPDF4LLM (layout-aware parsing)
  - 33 ArXiv papers ‚Üí 1541 chunks
  - Token-based chunking: 500 tokens, 50 overlap (tiktoken)
  - Error handling for corrupted PDFs
- [X] Embedding generation (sentence-transformers)
  - Model: all-MiniLM-L6-v2 (384-dim)
  - Normalized embeddings for cosine similarity
- [X] Vector store setup (FAISS)
  - IndexFlatIP (inner product) - avoided L2 distance bug
  - Save/load functionality with metadata
- [X] Search quality verification
  - Test query: "What is RAG?"
  - Top-5 results all highly relevant
  - All from authoritative RAG survey paper

**Code Structure**:
- [X] Clean OOP design: PDFDocument, CorpusLoader, VectorStore classes
- [X] Separate modules: utils.py, data_loader.py, vector_store.py
- [X] Main scripts: build_index.py, test_search.py

**Documentation**:
- [X] Created comprehensive reference sheet: `references/day28-rag-implementation.md`
  - 4 critical technical decisions (PyMuPDF4LLM, tiktoken, IndexFlatIP, normalization)
  - 5 common pitfalls avoided
  - Interview talking points
- [X] Updated all progress files

**Day 7 Summary**:
- ‚è±Ô∏è Total time: ~2 hours (implementation + knowledge check + docs)
- üìä Knowledge check: 97% (A+) - Adam breakthrough, 8/10 perfect
- üîß RAG implementation: Production-quality pipeline complete
  - Stats: 1541 chunks, 384-dim embeddings, <10ms search
  - Quality: High-quality retrieval verified
- üìù Reference sheet: Comprehensive technical documentation
- üéØ Progress: Week 5 Day 1 complete, ready for Day 2 (BM25 + RRF fusion)

**Next Steps (Day 2)**:
- [ ] Add BM25 sparse retrieval (rank-bm25)
- [ ] Implement RRF fusion (combine dense + sparse)
- [ ] Compare retrieval quality: dense-only vs hybrid

**Project Details**:

**Full Project 4: RAG Q&A System** (Option B, ~12 hours over 2 weeks)
- **Data source**: 20-30 ArXiv papers on RAG/LLMs
- **Architecture**: Hybrid retrieval (Dense + BM25) ‚Üí RRF fusion ‚Üí GPT-3.5-turbo
- **Tech stack**: sentence-transformers, FAISS, rank-bm25, OpenAI API, Ragas
- **Evaluation**: Ragas framework (context precision, faithfulness, answer relevance) + retrieval metrics (Recall@K, MRR, NDCG)
- **Deployment**: Docker containerization, Streamlit Cloud
- **Timeline**: Weekend (1 hour light) + Week 5 (12 hours implementation)
- **Deliverables**: Working RAG system, comprehensive README, evaluation report, GitHub repo

**Rationale**:
- Respects weekend constraints (light knowledge checks 15-20 min/day)
- Leverages RAG mastery (99.2% - can implement immediately)
- Monday momentum (2-3 hour focused block when more time available)
- Portfolio-ready project showcasing end-to-end ML engineering
- Addresses evaluation metrics gap through Ragas integration

**Project Folder**: `/Users/menghanw/Documents/1. Projects/ü§ñ GenAI learning/projects/rag-qa-system/`
**Project Plan**: See `projects/rag-qa-system/project-plan.md` for complete specification

---

**Phase 1 Revised Deliverables** (End of Week 4): ‚úÖ **ALL ACHIEVED**
- ‚úÖ **Critical gaps closed**: 81.7% overall, all studied areas ‚â•80% (target: 80%+) **EXCEEDED**
- ‚úÖ **Interview readiness**: 85% overall (up from 75% Week 1) **EXCEEDED**
- ‚úÖ **Strong system design skills**: Can design 3-5 ML systems (YouTube, fraud detection, Instagram)
- üéØ **Projects**: 0 projects (Week 4 Day 5-7 to begin) - **Acceptable**, gap closure prioritized

**Key Success Metric**: ‚úÖ **Confidence to start applying to senior-level ML roles by Week 5** (target exceeded!)

**Key Insight**: **Gap closure > Projects** for senior roles. Projects demonstrate skills but don't close knowledge gaps.

**Week 4 Day 3-4 Decision**: Option A - Start Projects (all critical gaps closed, all targets met or exceeded)

---

## Phase 2: Modern AI & LLMs (Weeks 5-6)

‚ö†Ô∏è **SUBJECT TO CHANGE** based on Week 4 progress check
- If gaps remain after Week 4: Continue gap closure, defer Phase 2
- If gaps closed (85%+ readiness): Proceed with Phase 2 as planned OR compress/skip if ready to interview

**Original Goal**: Get current with LLM technology and build modern AI applications
**Time**: 10-20 hours total

**Gap Analysis Update**: Day 6-7 revealed we're already strong on LLM *applications* (75-85%) but weak on LLM *systems* (30%). Phase 2 may need to focus on systems-level topics instead of application-level.

### Week 5: LLM Fundamentals + Prompt Engineering

**Learning (3-4 hours)**:
- [ ] DeepLearning.AI: "ChatGPT Prompt Engineering for Developers" (2 hours)
- [ ] DeepLearning.AI: "Building Systems with ChatGPT API" (1-2 hours)
- [ ] HuggingFace Course Chapter 1: Transformer models
- [ ] Read: "Attention is All You Need" paper (at least abstract + intro)

**Hands-on (3-4 hours)**:
- [ ] Experiment with OpenAI API / Anthropic API
- [ ] Build simple chatbot with system prompts
- [ ] Try few-shot learning and prompt optimization
- [ ] Start Project 4: LLM-based application

**Resources**:
- DeepLearning.AI Short Courses: https://www.deeplearning.ai/short-courses/
- HuggingFace Course: https://huggingface.co/learn/nlp-course/
- OpenAI Cookbook: https://cookbook.openai.com/

---

### Week 6: RAG, Vector DBs & Fine-tuning

**Learning (3-4 hours)**:
- [ ] DeepLearning.AI: "LangChain for LLM Application Development"
- [ ] DeepLearning.AI: "Vector Databases from Embeddings to Applications"
- [ ] HuggingFace Course Chapter 2: Using transformers
- [ ] Read about RAG (Retrieval-Augmented Generation)

**Hands-on (4-5 hours)**:
- [ ] Complete Project 4: RAG system or fine-tuned model
  - Option A: Document Q&A system with vector DB
  - Option B: Fine-tune small model (BERT/DistilBERT) for specific task
  - Option C: Multi-agent system with LangChain
- [ ] Polish Project 4 for portfolio

**Phase 2 Deliverable**:
- ‚úÖ 1 modern LLM application on GitHub
- ‚úÖ Can discuss: transformers, attention, embeddings, RAG, fine-tuning
- ‚úÖ Familiar with LangChain, vector DBs, prompt engineering

---

## Phase 3: Interview Prep (Weeks 7-10)

‚ö†Ô∏è **SUBJECT TO CHANGE** based on Week 4-6 progress
- May start earlier (Week 5-6) if gaps close fast
- System design already practiced in Week 3, ML coding validated in Week 1
- Main focus: Mock interviews and application preparation

**Goal**: Master interview formats and build interview-specific skills
**Time**: 28-40 hours total (may be compressed to 2-3 weeks)

### Week 7: ML System Design (Part 1)

**Learning (2-3 hours)**:
- [ ] Read "Machine Learning System Design Interview" (Chapters 1-3)
- [ ] Study ML system design framework
- [ ] Watch example system design interviews on YouTube

**Practice (4-5 hours)**:
- [ ] Practice problem: Design a video recommendation system
- [ ] Practice problem: Design a search ranking system
- [ ] Write out full solutions with diagrams
- [ ] Review sample solutions and compare

**Topics to master**:
- Data collection and labeling
- Feature engineering pipeline
- Model selection and training
- Evaluation metrics and A/B testing
- Deployment and serving architecture
- Monitoring and retraining

---

### Week 8: ML System Design (Part 2) + ML Coding Prep

**System Design Practice (3-4 hours)**:
- [ ] Practice problem: Design a fraud detection system
- [ ] Practice problem: Design a feed ranking system (e.g., Facebook/LinkedIn)
- [ ] Record yourself explaining solutions (simulate interview)

**ML Coding Practice (3-4 hours)**:
- [ ] Implement linear regression from scratch (no sklearn)
- [ ] Implement logistic regression from scratch
- [ ] Implement k-means clustering from scratch
- [ ] Implement decision tree from scratch (optional)
- [ ] Practice on LeetCode ML problems (if available)

**Resources**:
- ML System Design questions: See `ML-System-Design-Questions.md`
- ML Coding questions: See `ML-Coding-Questions.md`

---

### Week 9: ML Theory + Algorithm Implementation

**Theory Review (3-4 hours)**:
- [ ] Review bias-variance tradeoff
- [ ] Review regularization (L1, L2, dropout)
- [ ] Review optimization algorithms (SGD, Adam, etc.)
- [ ] Review evaluation metrics (precision, recall, F1, AUC-ROC, etc.)
- [ ] Review common ML algorithms and when to use them
- [ ] Go through 30+ theory questions in `ML-Theory-Questions.md`

**Coding Practice (3-4 hours)**:
- [ ] **Implement neural network with backpropagation from scratch** (2-3 hours priority)
  - **Rationale**: Week 2 Day 9 practice exercises revealed need for hands-on coding beyond conceptual derivation
  - Forward pass: Input ‚Üí Hidden layer(s) ‚Üí Output
  - Backward pass: Derive all gradients (‚àÇL/‚àÇW, ‚àÇL/‚àÇb) using chain rule
  - Manual gradient check: Compare analytical gradients to numerical gradients
  - Test on simple dataset (XOR or MNIST)
  - **Goal**: Solidify backprop understanding with actual implementation
- [ ] Implement cross-validation from scratch
- [ ] Practice feature engineering problems
- [ ] Practice data preprocessing tasks (handling missing data, scaling, encoding)

---

### Week 10: Mock Interviews + Portfolio Polish

**Mock Interviews (4-5 hours)**:
- [ ] Schedule 2-3 mock interviews on Pramp or interviewing.io
- [ ] Do at least one ML system design mock
- [ ] Do at least one ML coding mock
- [ ] Record feedback and areas for improvement

**Portfolio Work (3-4 hours)**:
- [ ] Final polish on all 4 projects
- [ ] Write comprehensive READMEs with:
  - Problem statement
  - Approach and methodology
  - Results and evaluation
  - Technologies used
  - Future improvements
- [ ] Add visualizations and demo gifs/screenshots
- [ ] Ensure code is clean and well-commented

**Resume & LinkedIn (1-2 hours)**:
- [ ] Update resume with ML projects
- [ ] Update LinkedIn with skills and projects
- [ ] Prepare 2-minute elevator pitch

---

## Phase 4: Active Job Search (Weeks 11-12+)

‚ö†Ô∏è **SUBJECT TO CHANGE** - May start as early as Week 8-9 if readiness hits 85%+
- Gap analysis showed 75% readiness after Week 1
- Target: 85%+ after Weeks 2-4 (gap closure)
- Can start applying to mid-level roles while continuing senior-level prep

**Goal**: Apply to jobs, interview, and iterate based on feedback
**Time**: 10-20+ hours/week

**Flexible Strategy**:
- **Week 8-10**: Start applications to mid-level ML Engineer roles (already 75% ready)
- **Week 10-12+**: Apply to senior roles after closing LLM systems gap
- Use early interviews as practice, iterate based on feedback

### Week 11-12: Applications + Interviews

**Applications (2-3 hours/week)**:
- [ ] Apply to 10-15 positions per week
- [ ] Target: ML Engineer, Applied Scientist, AI Engineer roles
- [ ] Track applications in spreadsheet

**Interview Practice (3-4 hours/week)**:
- [ ] Continue mock interviews
- [ ] Review and practice weak areas
- [ ] Practice explaining projects clearly and concisely
- [ ] Prepare behavioral stories using STAR format

**Ongoing Learning (2-3 hours/week)**:
- [ ] Stay current: read ML papers, blog posts
- [ ] Follow ML on Twitter/LinkedIn
- [ ] Participate in ML communities (Reddit, Discord)
- [ ] Continue Fast.AI or other courses if time permits

**After Each Interview**:
- [ ] Document questions asked
- [ ] Identify knowledge gaps
- [ ] Study gaps immediately
- [ ] Update interview prep materials

---

## üìä Revised Timeline Summary (Updated Day 8 - Week 2 Start)

**Current Status** (End of Week 1 + Day 8):
- ‚úÖ **Interview Readiness**: 75% (B+)
- ‚úÖ **Strong Areas**: ML fundamentals (95%), classical ML (90%), deep learning (85%), NLP/transformers (85%)
- ‚ùå **Critical Gaps**: LLM systems (0% know, 82% dunno), statistical testing (65%), advanced RAG (30%)
- üéØ **Target**: 80-85% readiness for ML Engineer roles by Week 4

**Revised Timeline** (Updated after Week 4 Day 3-4 completion):

| Week | Focus | Goal | Readiness Target | Status |
|------|-------|------|------------------|--------|
| **Week 1** | Algorithm implementations + gap analysis | Validate skills, identify gaps | 75% ‚Üí Baseline | ‚úÖ Completed |
| **Week 2** | **5 days LLM systems + 2 days statistics** | Interview-ready in LLM systems (60-70%) | 75% ‚Üí 78% | ‚úÖ Completed (83% achieved) |
| **Week 3** | System design + ML infrastructure + statistics | Strengthen system design to 85% | 78% ‚Üí 82% | ‚úÖ Completed |
| **Week 4 Day 1-2** | Advanced RAG | Close RAG gap (21% ‚Üí 55%+) | 82% ‚Üí 83% | ‚úÖ Completed (99.2% RAG!) |
| **Week 4 Day 3-4** | Gap reassessment | Measure progress, decide next steps | 83% ‚Üí **85%** | ‚úÖ **COMPLETED** ‚≠ê |
| **Week 4 Day 5-7** | **Start Projects** | Build portfolio project | Maintain 85%+ | üéØ **READY TO BEGIN** |
| **Week 5-6** | Continue projects OR advanced topics | Build 1-2 portfolio projects | Maintain 85%+ | üìÖ Planned |
| **Week 7-10** | Mock interviews + applications | Practice + iterate | 85%+ ‚Üí 90% | üìÖ Planned |
| **Week 5+** | **Start job search (senior-level roles)** | Apply to target companies | **85% achieved** ‚úÖ | üéØ **READY** |

**Key Decisions Made**:
1. ‚úÖ **Day 8 Topic Coverage Check** revealed 82% dunno in LLM Systems ‚Üí foundational learning needed
2. ‚úÖ **Week 2 extended to 5 days** for LLM Systems (was 2 days) - focus on 24 high-impact topics
3. ‚úÖ **Advanced RAG moved to Week 4** (was Week 2 Day 4-5)
4. ‚úÖ **Week 3-4 marked subject to adjustment** based on Week 2 progress
5. ‚úÖ **Gap closure > Projects** - reassessed at Week 4 checkpoint
6. ‚úÖ **Week 4 Day 3-4 Decision**: Start Projects (Option A) - all critical gaps closed ‚≠ê

**Success Metrics**: ‚úÖ **ALL ACHIEVED**
- **Week 2 (Day 14)**: LLM systems 83% ‚úÖ (exceeded 60-70% target), statistics 81.7% ‚úÖ
- **Week 4 (Day 25)**: **85% readiness** ‚úÖ (exceeded 80-85% target)
  - LLM Systems: 89.4% ‚úÖ
  - Statistics: 81.7% ‚úÖ
  - Advanced RAG: 99.2% ‚úÖ‚úÖ
  - ML Infrastructure: 90.0% ‚úÖ
  - System Design: 86% ‚úÖ
- **Week 4 Day 5-7**: Start portfolio projects üéØ
- **Week 5+**: **Ready to apply to senior-level ML roles** ‚úÖ

---

## Weekly Schedule Template

### For 7-8 hours/week:

**Weekdays (3-4 hours)**:
- Monday: 1 hour - Watch lectures/read materials
- Tuesday: 1 hour - Coding exercises or practice problems
- Wednesday: 1 hour - Watch lectures/read materials
- Thursday: 1-2 hours - Coding exercises or practice problems

**Weekend (4-5 hours)**:
- Saturday: 2-3 hours - Project work
- Sunday: 2 hours - Project work or interview practice (later phases)

### For 10 hours/week:

Add:
- Friday: 1 hour - Review week's learnings, plan next week
- Weekend: +1-2 hours more on projects

---

## Key Milestones & Checkpoints

**End of Week 4**:
- ‚úÖ 3 ML projects completed
- ‚úÖ Comfortable with ML pipeline end-to-end
- ‚úÖ Can train, evaluate, and compare models

**End of Week 6**:
- ‚úÖ 4 projects total (including 1 LLM project)
- ‚úÖ Can discuss modern AI/LLM concepts
- ‚úÖ Portfolio ready to show

**End of Week 8**:
- ‚úÖ Can design ML systems for common problems
- ‚úÖ Can implement ML algorithms from scratch
- ‚úÖ Ready for technical interviews

**End of Week 10**:
- ‚úÖ Completed mock interviews
- ‚úÖ Resume and LinkedIn updated
- ‚úÖ Ready to apply

**Week 11+**:
- ‚úÖ Actively interviewing
- ‚úÖ Iterating based on feedback

---

## Resources Summary

### Primary Courses:
1. **Fast.AI Practical Deep Learning** - https://course.fast.ai/
2. **DeepLearning.AI Short Courses** - https://www.deeplearning.ai/short-courses/
3. **HuggingFace NLP Course** - https://huggingface.co/learn/nlp-course/

### Supplementary:
4. **Stanford CS229** - https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU
5. **DeepLearning.AI ML Specialization** (Coursera) - If you need more structure

### Books & Readings:
- "Machine Learning System Design Interview" by Ali Aminian & Alex Xu
- "Designing Machine Learning Systems" by Chip Huyen
- Papers: "Attention is All You Need", "BERT", "GPT" papers (at least abstracts)

### Practice Platforms:
- **LeetCode** - For coding practice
- **Kaggle** - For datasets and competitions
- **Pramp / interviewing.io** - For mock interviews

### Communities:
- r/MachineLearning, r/learnmachinelearning (Reddit)
- ML Discord servers
- HuggingFace community

---

## Interview Preparation Materials

Reference these files throughout your prep:

1. **`ML-System-Design-Questions.md`** - Practice system design problems
2. **`ML-Coding-Questions.md`** - Practice coding problems
3. **`ML-Theory-Questions.md`** - Review theory concepts
4. **`Behavioral-Questions.md`** - Prepare behavioral responses
5. **`Project-Ideas.md`** - Detailed project specifications

---

## Tips for Success

### Consistency > Intensity
- Block time on your calendar
- 1 hour/day is better than 7 hours on Sunday
- Build a habit, don't rely on motivation

### Projects > Passive Learning
- Interviewers care about what you've built
- "Learning by doing" is faster and sticks better
- Each project teaches you 10x more than watching lectures

### Leverage Your Background
- Production ML experience is valuable credibility
- **Continuous ML engagement**: Traditional ML (BERT, neural networks) ‚Üí Modern AI (LLM/RAG)
- Emphasize: production ML experience + modern AI stack (LLMs, RAG, evaluation frameworks)
- Position as: "From ML model development to ML integration, now returning to model development"
- Hands-on experience across the full ML spectrum

### Interview Strategy
- Start applying in Week 6-7 (don't wait until "ready")
- Apply broadly, practice with companies you care less about first
- Each interview is learning - document and improve
- Don't get discouraged by rejections - it's a numbers game

### Network
- Reach out to former colleagues who moved to ML roles
- LinkedIn outreach to recruiters and hiring managers
- Attend ML meetups (virtual or in-person)
- Contribute to open-source ML projects

---

## Adjustment Guidelines

**If you're moving faster than planned**:
- Add more projects (aim for 5-6 total)
- Go deeper on topics (read papers, implement more algorithms)
- Start applying earlier (Week 4-5)

**If you're moving slower**:
- Focus on breadth over depth
- Prioritize: 3 projects minimum + system design + coding
- Skip optional items (implementing from scratch, etc.)
- Extend timeline to 14-16 weeks

**If you get interviews early**:
- Pause coursework
- Focus 100% on interview prep for that company
- Do targeted practice on their interview format
- Don't decline interviews - treat early ones as practice

---

## Progress Tracking

Use this checklist to track your progress:

### Projects:
- [ ] Project 1: Image Classification
- [ ] Project 2: Text Classification
- [ ] Project 3: Structured Data
- [ ] Project 4: LLM Application

### Interview Skills:
- [ ] Can design ML systems (5+ practice problems done)
- [ ] Can implement ML algorithms from scratch (5+ done)
- [ ] Can answer ML theory questions (reviewed 30+ questions)
- [ ] Prepared behavioral stories (5+ stories ready)

### Applications:
- [ ] Resume updated
- [ ] LinkedIn updated
- [ ] 20+ applications submitted
- [ ] 5+ phone screens completed
- [ ] 3+ onsite/virtual onsites completed

---

## Next Steps

1. **Start today** with Week 1, Day 1 tasks
2. **Set up tracking** - Use this document or create a Notion/spreadsheet
3. **Block calendar** - Schedule your 7-10 hours/week now
4. **Join communities** - Get support and accountability
5. **Tell someone** - Accountability partner or mentor

---

**Last Updated**: 2025-11-22 (Week 4 Day 3-4 gap reassessment complete)
**Created for**: Senior SWE ‚Üí ML Engineer transition
**Timeline**: 12 weeks (adjustable)
**Current Status**: 85% interview readiness achieved, ready for senior-level ML Engineer roles ‚úÖ

---

## Daily Knowledge Check Protocol

**NEW: Starting Day 5** (2025-10-31)

At the end of each study day:
1. Complete theory/implementation work
2. **Knowledge Check** (10-15 min):
   - 70% today's content
   - 30% previous content (spaced repetition based on forgetting curve)
3. Create quick reference sheet
4. Update progress files

**Purpose**: Spaced repetition to maximize retention and identify gaps early

**Details**: See `Daily-Knowledge-Check-Protocol.md`
